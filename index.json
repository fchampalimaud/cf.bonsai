{
  "articles/about_packages.html": {
    "href": "articles/about_packages.html",
    "title": "About Packages | CF.Bonsai",
    "keywords": "About Packages Under construction..."
  },
  "articles/harp_old_text.html": {
    "href": "articles/harp_old_text.html",
    "title": "| CF.Bonsai",
    "keywords": "Harp is a standard for asynchronous real-time data acquisition and experimental control in neuroscience. It includes specifications for a lightweight and versatile binary communication protocol, a set of common registers for microcontroller firmware, and a clock synchronization protocol. The Harp ecosystem currently includes devices to configure, control, and collect data from a wide range of peripheral devices such as cameras, LEDs, nosepokes, and motors. Combining Harp devices is an easy way to extend experimental setup functionality with integrated timestamp synchronisation across devices. Harp is being developed as a cross-institutional collaboration to develop an ecosystem of high-performance devices that make it easy for scientists to synchronize and extend the functionality of their setups."
  },
  "articles/install_bonsai.html": {
    "href": "articles/install_bonsai.html",
    "title": "| CF.Bonsai",
    "keywords": "Bonsai Installation Before you can use the examples on this website you need to install the following: Download and install the latest version of the Bonsai installer. Install the Starter package: Open your Bonsai application Go to Manage Packages In Package Sources select 'Bonsai' Search for the Starter package using the browser Install the package Install any other packages required by the specific examples you want to run. Documentation Further information can be found here: Documentation. Bonsai discussion forum Bonsai Language Guide"
  },
  "articles/install_harp.html": {
    "href": "articles/install_harp.html",
    "title": "| CF.Bonsai",
    "keywords": "Harp Installation Before you can use Harp devices in Bonsai you need to install the following: Install Harp USB drivers from here Install the generic Harp packages for Bonsai: Open your Bonsai application Go to Manage Packages In Package Sources select Bonsai Packages Search for Harp Install Harp Library and Harp Design Library Install the specific Harp device packages for Bonsai: In Package Sources select nuget.org Search for your desired device (eg 'Harp Behavior') Install the package Documentation Further information can be found here: Harp-Tech. Harp Protocol CF Harp Devices Using the Bonsai.Harp packages Python data interface Q&A, community, forum"
  },
  "articles/welcome.html": {
    "href": "articles/welcome.html",
    "title": "| CF.Bonsai",
    "keywords": "Welcome Welcome to CF.Bonsai, a website from the Champalimaud Foundation that contains annotated examples of recurring neuroscience tasks programmed in Bonsai. Many of these examples make use of the Harp hardware protocol to interface with a variety of peripheral devices. Getting started Start by installing the necessary Bonsai and Harp software from the Getting Started menu on the left panel. Then, find your example of choice, and follow the instructions to run it. Every example can be copied directly to Bonsai, and includes a set of annotations that explain the most significant parts of the code. If the example involves hardware (as those of Harp) additional electrical diagrams are provided with the necessary connections between the components. Contributions You can place suggestions for new examples, or report any issues concerning the existing examples here. If you want to contribute with your own examples please follow the guidelines described in the cf.bonsai repository. For issues concerning Bonsai, please use the official channels. Bonsai Bonsai is an open-source visual language for reactive programming. It is lightweight and easy to use with a variety of packages and modules for interfacing with hardware and for real-time processing and manipulation of data streams. More information about Harp can be found at bonsai-rx.org. Harp Harp is an open-source standard for asynchronous real-time data acquisition and experimental control in neuroscience. The Harp ecosystem currently includes devices to configure, control and collect data from a wide range of peripheral devices such as cameras, LEDs, nosepokes and motors. More information about Harp can be found at harp-tech.org."
  },
  "docfx-tools/README.html": {
    "href": "docfx-tools/README.html",
    "title": "docfx-tools | CF.Bonsai",
    "keywords": "docfx-tools A docfx template for package documentation, patching the modern template to provide stylesheets and scripts for rendering custom workflow containers with copy functionality. How to use To include this template in a docfx website, first clone this repository as a submodule: git submodule add https://github.com/bonsai-rx/docfx-tools bonsai Then modify docfx.json to include the template immediately after the modern template: \"template\": [ \"default\", \"modern\", \"bonsai/template\", \"template\" ], Finally, import and call the modules inside your website template/public folder. main.css @import \"workflow.css\"; main.js import WorkflowContainer from \"./workflow.js\" export default { start: () => { WorkflowContainer.init(); } } Powershell Scripts This repository also provides helper scripts to automate several content generation steps for package documentation websites. Exporting workflow images Exporting SVG images for all example workflows can be automated by placing all .bonsai files in a workflows folder and calling the below script pointing to the bin directory to include. A bonsai environment is assumed to be available in the .bonsai folder in the repository root. .\\modules\\Export-Image.ps1 \"..\\src\\PackageName\\bin\\Release\\net472\""
  },
  "index.html": {
    "href": "index.html",
    "title": "",
    "keywords": ""
  },
  "workflows/BonsaiExamples/Audio/PlayTone/PlayTone.html": {
    "href": "workflows/BonsaiExamples/Audio/PlayTone/PlayTone.html",
    "title": "Play Tone | CF.Bonsai",
    "keywords": "Play Tone Summary This example demonstrates how to play a tone with fixed frequency and duration whenever a key is pressed. Workflow Details Plays a tone whenever 'A' is pressed. Generates a sinusoidal wave form with 44100 samples with amplitude of 10000 and frequency of 1000Hz. Given that the sampling rate is set to 44100Hz, the wave generated will allow the tone to last for 1s. Plays the tone. Follow up The example shows how to modify the frequency and durations to obtain different tones on-the-fly."
  },
  "workflows/BonsaiExamples/Audio/SoundCalibration/SoundCalibration.html": {
    "href": "workflows/BonsaiExamples/Audio/SoundCalibration/SoundCalibration.html",
    "title": "Play Tone | CF.Bonsai",
    "keywords": "Play Tone Summary This example demonstrates how to play a tone with fixed frequency and duration whenever a key is pressed. Workflow Details Plays a tone whenever 'A' is pressed. Generates a sinusoidal wave form with 44100 samples with amplitude of 10000 and frequency of 1000Hz. Given that the sampling rate is set to 44100Hz, the wave generated will allow the tone to last for 1s. Plays the tone. Follow up The example shows how to modify the frequency and durations to obtain different tones on-the-fly."
  },
  "workflows/BonsaiExamples/BonVision/MovingCircle/MovingCircle.html": {
    "href": "workflows/BonsaiExamples/BonVision/MovingCircle/MovingCircle.html",
    "title": "Moving Circle | CF.Bonsai",
    "keywords": "Moving Circle Summary This example demonstrates how to draw a circle in Shaders and update its position according to mouse movements. Workflow Details Creates and initializes a simple shaders window with the standard resources necessary to draw the circle. Creates an orthographic view with the normalized window coordinates, and sets up a behavior subject 'DrawScene' to be used whenever an update is to occur. Draws a circle in the current scene. Modifies the position of the circle according to the position of mouse. The position of the mouse in the screen is normalized to the shader window coordinates to facilitate the interaction. Move the mouse over the Shaders window to observe the result. Follow up For more information on BonVision visit the website."
  },
  "workflows/BonsaiExamples/BonVision/MovingGratings/MovingGratings.html": {
    "href": "workflows/BonsaiExamples/BonVision/MovingGratings/MovingGratings.html",
    "title": "Moving Gratings | CF.Bonsai",
    "keywords": "Moving Gratings Summary This example demonstrates how to create gratings of different orientations on the press of a key. Workflow Details Creates and initializes a simple shaders window with the standard resources necessary to draw the gratings. Creates an orthographic view with the normalized window coordinates, and sets up a behavior subject 'DrawScene' to be used whenever an update is to occur. Draws a circle with a moving grating at the center of the current scene (check the grating settings in the node properties). Sets the orientation of the grating to horizontal when 'A' is pressed. Sets the orientation of the grating to vertical when 'S' is pressed."
  },
  "workflows/BonsaiExamples/DAQmx/AIAOSynchronization/AIAOSynchronization.html": {
    "href": "workflows/BonsaiExamples/DAQmx/AIAOSynchronization/AIAOSynchronization.html",
    "title": "AI/AO Synchronization | CF.Bonsai",
    "keywords": "AI/AO Synchronization Summary This example demonstrates how to send analog outputs and receive analog inputs from a National Instruments board in a synchronized way. Workflow Details Reads analog inputs from a NIDAQ board. The ports to be read are defined in the Channels property. In this example we are using analog input 0 (ai0). The node is set to collect analog inputs at 100000Hz divided in buffers of 10000 samples. The SignalSource property, which defines the clock signal, is set to be the same as that used for the analog output ports (see 2.3). Generates a sawtooth function of with amplitude of 0.7 and frequency of 1Hz (in a buffer with size 10000), converts it into a step function and sends it to the analog output 0 (ao0). Creates the step function by rounding the input float values (which are in the range [0,0.7]) to integer values of 0 or 1. Converts the signal back to floats and amplifies them by a factor of 3. This the final voltage values set in the analog output (2.3) Sends a buffer with a step signal to the analog output port 0 (ao0) every 100ms, generating a total of 10 steps cycles per second. Testing The synchronization of the two signals can easily be tested by connecting the analog output to a LED and the analog input to a light-sensitive photodiode. If the result is correct, the two waves should be phase-locked to each other as shown below.* *Note though that you could potentially observe a constant phase-shift between them; this is because at the moment the DAQmx package does not allow yet for using the same trigger to initiate the analog input and output ports."
  },
  "workflows/BonsaiExamples/DAQmx/DigitalInputsNonBuffered/DigitalInputsNonBuffered.html": {
    "href": "workflows/BonsaiExamples/DAQmx/DigitalInputsNonBuffered/DigitalInputsNonBuffered.html",
    "title": "Digital Inputs (Non-Buffered) | CF.Bonsai",
    "keywords": "Digital Inputs (Non-Buffered) Summary This example demonstrates how to read two digital inputs from a National Instruments board in a non-buffered way (ie. sample-by-sample). Workflow Details Sets the period at which samples will be read from the NI board (50ms in this example). Reads two digial inputs from a NIdaq board. The ports to be read are defined in the Channels property. In this example we are using digital ports [your-dev]/port0/line0 and [your-dev]/port0/line1. Parses the Mat data from the DigitalInput node to obtain only values pertaining line0 (above) and line1 (below). Converts the Scalar data in 3 into double. The Scalar.Val0 is a byte where all bits are zero except the bit that has the same index as the line number; that bit contains the actual value of the digital port. Converts the double value in 4 to boolean. Note: This example used a NI USB-6008 board."
  },
  "workflows/BonsaiExamples/DataTypes/ArrayManipulation/ArrayManipulation.html": {
    "href": "workflows/BonsaiExamples/DataTypes/ArrayManipulation/ArrayManipulation.html",
    "title": "Array Manipulation | CF.Bonsai",
    "keywords": "Array Manipulation Summary This example demonstrates how to create an array, add elements to it and remove elements from it. Workflow Details Create an int array with one element. Receives a single int value and terminates the sequence. Closing the sequence is essential to create the array (see 1.2). Creates an array with the single int value received. Initializes the subject MyArray with the int array created. Adds a new int value to the array whenever 'A' is pressed. Gets the current number of 'A' key presses. Creates a new int array with the elements in MyArray added by the current number of key presses. Updates MyArray with the new array created. Removes the last element from MyArray whenever 'S' is pressed. Creates a new array without the last element. Updates MyArray with the new int array created. Outputs the current values of the array at 200ms intervals. Enables the visualization of the current content of MyArray. Double-click on this node to visualize the current content of the Int array. Extracts the length of the current array. Double-click on this node to visualize it. Notes The key elements of this workflow are the Concat and ToArray nodes from the Reactive package. Concat produces a flat sequence of values with the individual elements of an array, while ToArray composes an array out of a flat sequence of values (insofar as that sequence terminates). Mastering these two nodes is key to understanding this example."
  },
  "workflows/BonsaiExamples/DataTypes/BasicTypeConversions/BasicTypeConversions.html": {
    "href": "workflows/BonsaiExamples/DataTypes/BasicTypeConversions/BasicTypeConversions.html",
    "title": "Basic Type Conversions | CF.Bonsai",
    "keywords": "Basic Type Conversions Summary This example demonstrates how to convert across the different numeric data types using direct CSharp expressions in the ExpressionTransform node. Workflow Details Generates an int value Converts the int into a float value using the method Convert.ToSingle() method Converts the float into a double value using the method Convert.ToDouble() method Converts the double into a string using the method Convert.ToString() method Converts the string back to an int value using the method Convert.ToIt32() method Converts the int into a time value (in ms) using the method TimeSpan.FromMilliseconds() method The it argument passed to each method inside the ExpressionTransform nodes represents the actual input value of the node. Verify the output type of each node (by right-clicking on the node) and use the TextVisualizer to best inspect the output of each node."
  },
  "workflows/BonsaiExamples/DataTypes/CreateIntArray/CreateIntArray.html": {
    "href": "workflows/BonsaiExamples/DataTypes/CreateIntArray/CreateIntArray.html",
    "title": "Create Int Array | CF.Bonsai",
    "keywords": "Create Int Array Summary This example demostrates how to create an array with N elements whenever a key is pressed. Workflow Details Creates an Int array whenever 'A' is pressed. Creates an array of 10 elements using a Range node (count=10) followed by a ToArray node, inside a SelectMany node (see inside the SelectMany node). Gets the values in of the 3 first indexes of each array generated in 2. Zips the 3 elements of each array index for visualization purposes. Double-click on this node to visualize the first three elements of the array."
  },
  "workflows/BonsaiExamples/DataTypes/GroupNEventsIntoArray/GroupNEventsIntoArray.html": {
    "href": "workflows/BonsaiExamples/DataTypes/GroupNEventsIntoArray/GroupNEventsIntoArray.html",
    "title": "Group N Events Into Array | CF.Bonsai",
    "keywords": "Group N Events Into Array Summary This example demostrates how to group a number of events and output them as arrays. Workflow Details Generates a counter that emits a new value every 0.5s. Creates a group for every 3 events, and propagates each group separately. Transforms every group of 3 events into an array of 3 elements. This is done using a Take node (Count=3) followed by a ToArray node, inside a CreateArray group node (see inside the CreateArray node). Returns the values in of the 3 indexes of each array generated in 3. Zips the elements of each array index for visualization purposes. Double-click on this node to visualize the first three elements of the array."
  },
  "workflows/BonsaiExamples/DataTypes/StreamsToMat/StreamsToMat.html": {
    "href": "workflows/BonsaiExamples/DataTypes/StreamsToMat/StreamsToMat.html",
    "title": "Streams to Mat | CF.Bonsai",
    "keywords": "Streams to Mat Summary This example shows how the make two streams of data converge into a OpenCV.Net.Mat data type. Workflow Details Creates a random distribution. Generates a random value every 0.5s, multiplies it by two, and combines the two into a single Mat value. Combines every value from the Timer with the distribution created in 1. Selects the distribution. Samples one value from the distribution. Multiplies the value by 2. Combines the values from 3 and 4. Creates a buffer every time two elements are received as a Mat. Transposes the buffer for visualization purposes. Double-click on this node to visualize the resulting Mat content."
  },
  "workflows/BonsaiExamples/GUI/ImageThresholdSlider/ImageThresholdSlider.html": {
    "href": "workflows/BonsaiExamples/GUI/ImageThresholdSlider/ImageThresholdSlider.html",
    "title": "Image Threshold Slider | CF.Bonsai",
    "keywords": "Image Threshold Slider Summary This example demonstrates how to combine different GUI elements into a single window to control and visualize the output of image thresholding. Workflow Details Creates a workflow to perform simple image thesholdig. Converts the image to grayscale Creates a BehaviorSubject to receive the grayscale images. This subject will used for the GUI panel (see 2.3). Thresholds the current image according with the latest values received in the SliderValue subject node (see 2.1). Creates a BehaviorSubject to receive the thresholded images. This subject will used for the GUI panel (see 2.4). Creates a 2x2 panel to encorporate all the GUI elements. Double-lick on this node to visualize the GUI panel. Adds a slider element to the GUI. The value of the slider is sent to the SliderValue subject and it will modify the threshold value in 1.3. Adds a plot of the current threshold value set in the slider. Adds the grayscale image to the GUI. Adds the thresholded image to the GUI. Requirements You need to install the Bonsai.Gui package available in the nuget.org package source."
  },
  "workflows/BonsaiExamples/GUI/LineGraph/LineGraph.html": {
    "href": "workflows/BonsaiExamples/GUI/LineGraph/LineGraph.html",
    "title": "LineGraph | CF.Bonsai",
    "keywords": "LineGraph Summary This example demonstrates how to use the LineGraph GUI element to display real-time random data. Workflow Details Each second both the sine and cosine are calculated and zipped. The sine and cosine are mapped into the X and Y coordinates of a Point2d object. This is the object that must be input in the LineGraph. The LineGraph node responsible for the real-time visualizations. The LineGraph is mapped into a GraphPanel so that the settings from the LineGraph node are applied. Finally, the GraphPanel is mapped into a TableLayoutPanel. Requirements You need to install the Bonsai.Gui package available in the nuget.org package source. You need to install the following packages: Bonsai - GUI (from nuget.org) Bonsai - GUI ZedGraph (from nuget.org) Bonsai - Vision Library (from Bonsai Packages) Bonsai - Numerics Library (from Bonsai Packages)"
  },
  "workflows/BonsaiExamples/GUI/StartCameraSubPanel/StartCameraSubPanel.html": {
    "href": "workflows/BonsaiExamples/GUI/StartCameraSubPanel/StartCameraSubPanel.html",
    "title": "Start Camera Sub-Panel | CF.Bonsai",
    "keywords": "Start Camera Sub-Panel Summary This example demonstrates how to combine GUI elements with sub-panels to control the start and the stop of a camera using buttons. Workflow Details Creates a workflow to take frames from a camera when the start button is pressed. Takes images from the camera until the StopButton behavior subject* emits a value, which results in terminating the program. This happens when the stop button is pressed in the GUI (see 2.3). Creates a BehaviorSubject with the frames read from the camera. This will be used to visualize the frames in the GUI panel (see 2.4). Subscribes the preceeding workflow only when an even is received from the StartButton behavior subject (see 2.2). Creates two-panel GUI displaced in one row and two columns (1x2) to encorporate all the GUI elements. Double-lick on this node to visualize the GUI panel. Adds a sub-panel to the GUI with the two buttons. Adds a Start button to the sub-panel. Adds a Stop button to the sub-panel. Adds the image frames to the second panel of the GUI. Requirements You need to install the Bonsai.Gui package available in the nuget.org package source."
  },
  "workflows/BonsaiExamples/IO/BasicFileListProcessing/BasicFileListProcessing.html": {
    "href": "workflows/BonsaiExamples/IO/BasicFileListProcessing/BasicFileListProcessing.html",
    "title": "Basic File List Processing | CF.Bonsai",
    "keywords": "Basic File List Processing Summary This example demonstrates how to read data from a list of files, process each file individually and create new files with the output. It reads two files containing a number each, multiplies each number by two and creates two respective output files with the result. Workflow Summary This example demostrates how to read data from a list of files in a given directory, process each file individually to create a new set of corresponding output files. The output files will be placed in the same directory as the input files. Details Gets a list of filenames, with *.txt extension, from a given directory as string array.* Generates one event per each element in the string array. Processes each file individually. In this example, we read the number stored in each file, multiply it by two, and create a new file with the result with the string '_new' added to it. * Before running the code you need to download file1.txt and file2.txt to an empty directory, and modify the Path property in the GetFiles node accordingly. Follow up A more elaborated example for processing a list of files can be found here."
  },
  "workflows/BonsaiExamples/IO/ParseCSVFile/ParseCSVFile.html": {
    "href": "workflows/BonsaiExamples/IO/ParseCSVFile/ParseCSVFile.html",
    "title": "Parse CSV File | CF.Bonsai",
    "keywords": "Parse CSV File Workflow Summary BLA Details BLA Notes BLA"
  },
  "workflows/BonsaiExamples/IO/SerialFileListProcessing/SerialFileListProcessing.html": {
    "href": "workflows/BonsaiExamples/IO/SerialFileListProcessing/SerialFileListProcessing.html",
    "title": "Elaborate File List Processing | CF.Bonsai",
    "keywords": "Elaborate File List Processing Summary This example demonstrates how to serially process a list of files in a given directory (including subdirectories) and generate output files accordingly. Workflow Details Obtains a list of files from an input directory and initializes the necessary subjects to run the workflow. The input directory, the file search pattern, and the output directory can be set as properties of the group node. Processes each file sequentially. Selects the current file to be processed from the list of files. Prepares the output path and file stem that is used to create generate the subsequent output files. Processes the current file. Here, two output files are created for each input; one with the sum and the other with the multiplication of all the elements in the input file. Prepares the processing of the next file by updating the file index that will be used in the next iteration. Creates a delay in the processing of each file to allow the user to visualize the different processing stages (see 3 and 4). This node is used for visualization purposes only and it can safely be removed. Terminates the current iteration Subscribes the Current File subject to visualize the current file being processed. Subscribes the Status subject for visualization. The Status gets updated at every stage of the processing cycle. *Before running the code you need to download this folder, and modify the Input path property in the Init File Processing node in 1."
  },
  "workflows/BonsaiExamples/Numeric.Distributions/SampleDiscreteUniformDistribution/SampleDiscreteUniformDistribution.html": {
    "href": "workflows/BonsaiExamples/Numeric.Distributions/SampleDiscreteUniformDistribution/SampleDiscreteUniformDistribution.html",
    "title": "Sample Discrete Uniform Distribution | CF.Bonsai",
    "keywords": "Sample Discrete Uniform Distribution Summary This example demonstrates how to randomly sample from a discrete uniform distribution. Workflow Details Creates BehaviorSubject (MyDistribution) with a discrete uniform distribution with values ranging from 0 to 10. Samples randomly from MyDistribution when 'A' is pressed. Double-click on the Sample node, and press 'A' several times, to visualize the random numbers generated. If you want to repeat the same randomly sampled values everytime Bonsai is started, set the Seed property to any value in the CreateRandom node. Important Note: If you want to sample more than once from a given distribution do not connect the Sample node directly to the output of the CreateDiscreteUniform node. This will recreate the distribution everytime you take sample, which will produce undesired results."
  },
  "workflows/BonsaiExamples/Numeric.Distributions/SampleNormalDistribution/SampleNormalDistribution.html": {
    "href": "workflows/BonsaiExamples/Numeric.Distributions/SampleNormalDistribution/SampleNormalDistribution.html",
    "title": "Sample Normal Distribution | CF.Bonsai",
    "keywords": "Sample Normal Distribution Summary This example demonstrates how to randomly sample from a continuous normal distribution. Workflow Details Creates BehaviorSubject (MyDistribution) with a normal distribution with mean of 0 and standard deviation of 1. Samples randomly from MyDistribution when 'A' is pressed. Double-click on the Sample node, and press 'A' several times, to visualize the random numbers generated. If you want to repeat the same randomly sampled values everytime Bonsai is started, set the Seed property to any value in the CreateRandom node. Important Note: If you want to sample more than once from a given distribution do not connect the Sample node directly to the output of the CreateDiscreteUniform node. This will recreate the distribution everytime you take sample, which will produce undesired results."
  },
  "workflows/BonsaiExamples/Osc/UDPSendAndReceive/UDPSendAndReceive.html": {
    "href": "workflows/BonsaiExamples/Osc/UDPSendAndReceive/UDPSendAndReceive.html",
    "title": "Udp Server and Client | CF.Bonsai",
    "keywords": "Udp Server and Client Summary This example demonstrates how to setup an Osc server and an Osc client, and how messages can be sent from one to the other. Workflow Details Creates a udp communication channel. In this example, this channel will be listening in port 2323, the messages sent by localhost port 0. Creates a second udp communication channel. In this example, this channel will use port 0, to send messages to localhost port 2323. Generates and sends an Osc message with the x and y position of the mouse whenever the mouse moves. Emits events whenever a message is received with the x and y coordinates of the mouse. Follow-up In this example the communication is done via the localhost (i.e. it uses the same machine both for sending and receiving messages). However, the code can be run in different machines (as far as the machines are in the same LAN network), where the mouse movements executed in one can be sent to the other. To do this, you only need to change the localhost in UdpReceive and UdpSend by the IP respective addresses of each machine."
  },
  "workflows/BonsaiExamples/Vision/AnnotateArrayOfPoints/AnnotateArrayOfPoints.html": {
    "href": "workflows/BonsaiExamples/Vision/AnnotateArrayOfPoints/AnnotateArrayOfPoints.html",
    "title": "Annotate Array of Points | CF.Bonsai",
    "keywords": "Annotate Array of Points Summary This example demonstrates how to annotate an array of points using circles. Workflow Details Creates distribution to sample values for the position of each circle in the array. <<<<<<< HEAD Creates an array of points whenever 'A' is pressed and initializes an empty canvas. ======= Creates an array of points and creates an array of points whenever 'A' is pressed. 9d65925799bfcab8c746aed630a71dbab5f0ab10 3. Draws a circle centered in each point of the array. 1. Creates an event for each point in the array. 2. Associates each event with the current canvas (starting with the empty canvas for the first point in the array). 3. Sets the current canvas (Item2) for drawing a circle centered around the current point (Item1). 4. Draws the circle into the current canvas. 5. Updates the current canvas, which will allow for a new point to pass through the Zip node (3.2) 6. Terminates the drawing in the current canvas after 10 points have been drawn 6. Repeats the process, and waits for another set of points to arrive. 4. Draws the current canvas. Double-click on this node to visualize the output of the entire process. Follow-up The same framework could be used to write text in each of the points in the array using the node AddText. For more other annotation possibilities type 'Vision.Drawing' in the Bonsai toolbox."
  },
  "workflows/BonsaiExamples/Vision/CameraCalibration/CameraCalibration.html": {
    "href": "workflows/BonsaiExamples/Vision/CameraCalibration/CameraCalibration.html",
    "title": "Camera Calibration | CF.Bonsai",
    "keywords": "Camera Calibration Workflow Testing text"
  },
  "workflows/BonsaiExamples/Vision/ColumnwiseOperations/ColumnwiseOperations.html": {
    "href": "workflows/BonsaiExamples/Vision/ColumnwiseOperations/ColumnwiseOperations.html",
    "title": "Column-wise Operations | CF.Bonsai",
    "keywords": "Column-wise Operations Summary This example demonstrates how to project information of a matrix (in this case an image) into a single row vector using the max function. Workflow Details Convert the image to grayscale. Project the max values of each column to a single row vector. Follow-up In addition to the Max function one can use the Min, Sum, or Mean values. Row-wise operations can also be used by setting the Axis property in the Reduce node to 1."
  },
  "workflows/BonsaiExamples/Vision/ComposeImageLineByLine/ComposeImageLineByLine.html": {
    "href": "workflows/BonsaiExamples/Vision/ComposeImageLineByLine/ComposeImageLineByLine.html",
    "title": "Compose Image Line-by-Line | CF.Bonsai",
    "keywords": "Compose Image Line-by-Line Workflow Summary This example demonstrates how to compose full images by appending single lines. This could be useful, for instance, in the implementation of scanning microscopes. Details Initializes the behavior subjects necessary to run the example. It receives the Width and Height of the image as properties and it creates two subjects: Black Line, which consists of an image of a single black line, and Temporary Image which is initialized with the black line. In addition, it creates a random generator from which the pixel values will be sampled from. Creates an image with random values whenever 'A' is pressed. Initializes the Temporary Image subject to a single black line. Emits a value for every line to be generated. Generates a new line with random values for each value emited in 2.2. Appends the current line to the Temporary Image. Checks if all lines have been generated. When all lines have been generated, it crops the image to remove the black line. Creates a subject with the finished image."
  },
  "workflows/BonsaiExamples/Vision/CreateImageWithCircles/CreateImageWithCircles.html": {
    "href": "workflows/BonsaiExamples/Vision/CreateImageWithCircles/CreateImageWithCircles.html",
    "title": "Create Image with Circles | CF.Bonsai",
    "keywords": "Create Image with Circles Summary This example demonstrates how to compose an image with circles in it. Workflow Details Creates a new image with three circles everytime 'A' is pressed Creates a black canvas sized 100x100 Adds a white circle centered at (50,50) with a 40-pixel radius to the canvas Adds a white circle centered at (50,50) with a 20-pixel radius to the canvas Adds a white circle centered at (50,50) with a 10-pixel radius to the canvas Generates the three-circle image"
  },
  "workflows/BonsaiExamples/Vision/CroppedRegionAverage/CroppedRegionAverage.html": {
    "href": "workflows/BonsaiExamples/Vision/CroppedRegionAverage/CroppedRegionAverage.html",
    "title": "Cropped Region Average | CF.Bonsai",
    "keywords": "Cropped Region Average Summary This example demonstrates how to average the pixel intensity of a given region of an image. This could be used, for example, to identify whether a certain region of the space is being occupied by an animal. Workflow Details Opens the video file. * Crops the region of interest. Calculates the pixel average of the region of interest. Selects the first channel in the video. (The average is calculated independently for evey channel; in a grayscale image only the first channel has information.). Double-click both on the FileCapture and Val0 nodes to visualize the output of the process. *Download this file and set the FileName property of the FileCapture node accordingly. Follow-up"
  },
  "workflows/BonsaiExamples/Vision/DynamicCropping/DynamicCropping.html": {
    "href": "workflows/BonsaiExamples/Vision/DynamicCropping/DynamicCropping.html",
    "title": "Dynamic Cropping | CF.Bonsai",
    "keywords": "Dynamic Cropping Summary This example demonstrates how to set dynamically the values of a node's compound property, in this case the RegionOfInterest of the Crop node. Workflow Details Creates a black image with three white circles. Creates a black canvas. Adds three white circles. Creates an image with the filled image. Creates a BehaviorSubject, MyImage, with the three-circle image. Crops the image created according to a given region of interest. The coordinates of the cropping region can be set dynamically by changing the Int nodes from 2.1 to 2.4. Defines the X coordinate of the cropping region. Defines the Y coordinate of the cropping region. Defines the width of the cropping region. Defines the height of the cropping region. Defines the most up-to-date set of coordinate values of the cropping region. Pairs every image with latest cropping region. Propagates the current image and sets the RegionOfInterest property of the Crop node. Crops the current image according to the coordinates defined. Double-click on this node, and change the values of the Int nodes from 2.1 to 2.4 to visualize the output of the process."
  },
  "workflows/BonsaiExamples/Vision/ImageDifferenceAverage/ImageDifferenceAverage.html": {
    "href": "workflows/BonsaiExamples/Vision/ImageDifferenceAverage/ImageDifferenceAverage.html",
    "title": "Image Difference Average | CF.Bonsai",
    "keywords": "Image Difference Average Summary This example demonstrates how to subtract consecutive frames in a video, and average the absolute value of the result. Such a simple technique can be used to estimate the amount of motion in an animal. Workflow Details Opens the video file.* Creates a grayscale version of the frames. Skips one frame. Zips the current frame with the previous one. Subtracts the previous frame to the current one. Computes the absolute value of the pixels in the subtracted image. ** Averages all the pixels of the resulting image. *Download this file and set the FileName property of the FileCapture node accordingly. ** Often, the Power function is used instead of the absolute value."
  },
  "workflows/BonsaiExamples/Vision/MP4Writer/MP4Writer.html": {
    "href": "workflows/BonsaiExamples/Vision/MP4Writer/MP4Writer.html",
    "title": "MP4 Writer | CF.Bonsai",
    "keywords": "MP4 Writer Summary This example shows how to convert a MP4 video using FFMPEG. Workflow Details Before running the workflow, download and unzip the ffmpeg glp-local file from ffmpeg to a folder in your computer. Write the frames from a camera into ImageWriter, but in the path, instead of a file, you will add a pipe: \\\\.\\pipe\\video. Every frame that is written in the pipe is going to be sent the process in 2. Start a process where the filename points to the ffmpeg executable [ffmpeg]\\bin\\ffmpeg.exe and the arguments are those of ffmpeg. Here we are using: -y -f rawvideo -vcodec rawvideo -s 640x480 -r 30 -pix_fmt gray -i \\\\.\\pipe\\video -c:v libx264 -b:v 5212K -maxrate 5212K -bufsize 5M \"myvideo.mp4\" Options that might need to be adapted for your situation are: the size (width and height) of the input images (-s) the frame rate (-r) the input pixel format (-pix_fmt). Set to bgr24 for coloured images. the name of the output video (last parameter) in case the encoding is rather slow, you might want to append the option '-preset ultrafast' to speed it up. Other options that might be useful are: to remove audio (-an) set to an alternative codec (-vcodec mpeg4). Good for colored images. set the quality of the encoding (-qscale 0), with 0 being the best quality. Follow-up For additional information on the encoding options provided by ffmpeg consult the documentation."
  },
  "workflows/BonsaiExamples/Vision/MP4Writer/README.html": {
    "href": "workflows/BonsaiExamples/Vision/MP4Writer/README.html",
    "title": "| CF.Bonsai",
    "keywords": "Get ffpmeg from: https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip"
  },
  "workflows/BonsaiExamples/Vision/RegionTrackingHSV/RegionTrackingHSV.html": {
    "href": "workflows/BonsaiExamples/Vision/RegionTrackingHSV/RegionTrackingHSV.html",
    "title": "Region Tracking HSV | CF.Bonsai",
    "keywords": "Region Tracking HSV Summary This example demonstrates how to setup a simple tracker based on thresholding the HSV channels. Workflow Details Opens the video file.* Converts the image to HSV space (hue, saturation, value). This space is advantageous because it allows the user to separate colors, using only the hue channel, independently of the overall image brightness. Thresholds each of the HSV channels between a lower and an upper bound. Modify those bounds such that your particular object can be separated from the background. Finds regions of contiguous pixels in the thresholded image. You can set a minimum and/or a maximum number of acceptable contiguous pixels. Calculates a number of properties, for each region identified, such as position of the centroid, orientation, etc. Selects the largest region from the list of all identified regions. Selects the centroid region. To obtain this right-click on the LargestBinaryRegion node and select Output -> Centroid. Selects the X and Y coordinates from the Centroid node. Double-click on these nodes to visualize the position of the object in the image. *Download this file and set the FileName property of the FileCapture node accordingly. Visualization While the code is running, double-click on the FileCapture node to open the image visualizer, and drag the Centroid node into the it. This will overlay the centroid onto the object on the image visualizer. After you can left-click the image visualizer and it will furher overlay a trail of the centroid trajectory of the object. Follow-up See also the RegionTrakingRGB example."
  },
  "workflows/BonsaiExamples/Vision/RegionTrackingRGB/RegionTrackingRGB.html": {
    "href": "workflows/BonsaiExamples/Vision/RegionTrackingRGB/RegionTrackingRGB.html",
    "title": "Region Tracking RGB | CF.Bonsai",
    "keywords": "Region Tracking RGB Summary This example demonstrates how to setup a simple tracker based on thresholding the BGR channels. Workflow Details Opens the video file.* Thresholds each of the RGB channels between a lower and an upper bound. Modify those bounds such that your particular object can be separated from the background. Note that the order of the color channels in Bonsai is typically BGR. Finds regions of contiguous pixels in the thresholded image. You can set a minimum and/or a maximum number of acceptable contiguous pixels. Calculates a number of properties, for each region identified, such as position of the centroid, orientation, etc. Selects the largest region from the list of all identified regions. Selects the centroid region. To obtain this right-click on the LargestBinaryRegion node and select Output -> Centroid. Selects the X and Y coordinates from the Centroid node. Double-click on these nodes to visualize the position of the object in the image. *Download this file and set the FileName property of the FileCapture node accordingly. Visualization While the code is running, double-click on the FileCapture node to open the image visualizer, and drag the Centroid node into the it. This will overlay the centroid onto the object on the image visualizer. After you can left-click the image visualizer and it will furher overlay a trail of the centroid trajectory of the object. Follow-up See also the RegionTrackingHSV example."
  },
  "workflows/BonsaiExamples/Vision/SinglePixelValue/SinglePixelValue.html": {
    "href": "workflows/BonsaiExamples/Vision/SinglePixelValue/SinglePixelValue.html",
    "title": "Single Pixel Value | CF.Bonsai",
    "keywords": "Single Pixel Value Summary This example demonstrates how to obtain the intensity value of a single pixel in a grayscale image. Workflow Details Creates a grayscale canvas with a white circle in the middle when 'A' is pressed. Creates a grayscale image with a light gray circle in the middle when 'S' is pressed. Creates a grayscale image with a dark gray circle in the middle when 'D' is pressed. Transforms the canvas into an image. Retrieves the pixel information at the center (50,50). Retrieves the intensity value of the grayscale pixel, using the first channel (Val0).* To obtain this node, write-click over the ExpressionTransform node select Ouptut -> Val0. * For coloured images, the output values Val0, Val1, Val2, will contain the intensity values of the blue, green and red channels, respectively (the order might change for diferent images)."
  },
  "workflows/BonsaiExamples/Vision/TriggerPastFrames/TriggerPastFrames.html": {
    "href": "workflows/BonsaiExamples/Vision/TriggerPastFrames/TriggerPastFrames.html",
    "title": "Trigger Past Frames | CF.Bonsai",
    "keywords": "Trigger Past Frames Summary This example demonstrates how to capture a video of fixed duration that starts before a given trigger occurs, in this example a key press. Workflow Details Captures the frames from a camera. Delays the camera frames by 1 second, the time we will move back once the trigger occurs. Triggers a Window containing 2 seconds of video everytime 'A' is pressed. Because of the delay node in 2, the first frame of this video will start 1 second before the trigger and will end 1 second after. Retrieves the individual frames of the video. Double-click on this node to visualize the output of the process. * Note: A good way of testing this example is turning the camera to your hands as you press 'A'. * If you wanted to save the triggered videos, you can simply add a VideoWriter node inside the SelectMany node and set the Suffix property to a value different from 'None'."
  },
  "workflows/BonsaiExamples/Vision/VideoAnnotation/VideoAnnotation.html": {
    "href": "workflows/BonsaiExamples/Vision/VideoAnnotation/VideoAnnotation.html",
    "title": "Video Annotation | CF.Bonsai",
    "keywords": "Video Annotation Summary This example demonstrates how to add a circular marker to a camera image and save the resulting annotated video. Workflow Details Creates distribution to sample random point coordinates for the position of the circle. Creates a new circle position everytime the 'A' key is pressed. Capture camera images to a behavior subject. Creates a new canvas with the current frame and the marker every time a new frame is acquired. Sets the canvas size to the frame size. Adds current frame image to the canvas. Sets the x,y position of the circle and add it to the canvas. Draws the canvas into an image. Double-click in this node to visualize this node, and press 'A' several times, to observe the annotation process. Follow-up For more other annotation possibilities type 'Vision.Drawing' in the Bonsai toolbox."
  },
  "workflows/HarpExamples/BehaviorBoard/AnalogInput/AnalogInput.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/AnalogInput/AnalogInput.html",
    "title": "Analog Input | CF.Bonsai",
    "keywords": "Analog Input Summary This example demonstrates how to read analog input values from a potentiometer using the Harp Behavior board (see hardware schematics below). Workflow Details Creates a connection with the Behavior board. The PortName property in the Behavior node needs to be set to the COM device on the computer. Filters the messages from the Behavior board that pertain analog inputs. Selects the AnalogInput0 (AD0) from the list of possible analog inputs (see the output of the Parse node in 2). Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board has two analog input channels: AD0 and AD1. The maximum voltage allowed is 5V. In this example, the board receives an analog input signal from a potentiometer connected to AD0."
  },
  "workflows/HarpExamples/BehaviorBoard/CameraTrigger/CameraTrigger.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/CameraTrigger/CameraTrigger.html",
    "title": "Camera Trigger | CF.Bonsai",
    "keywords": "Camera Trigger Summary This example demonstrates how to trigger frames from a camera using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the acquisition frequency of the camera. Enables the camera triggers when 'A' is pressed. Disables the camera triggers when 'S' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can trigger two cameras using specific PWM signals in ports DO0 and DO1. The DOs output voltage is 5V. In this example, the board triggers frames from a PointGrey camera connected to DO0 (with a Hirose 6-pin GPIO connector on the back of the case)."
  },
  "workflows/HarpExamples/BehaviorBoard/DIOInput/DIOInput.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/DIOInput/DIOInput.html",
    "title": "DIO Input | CF.Bonsai",
    "keywords": "DIO Input Summary This example demonstrates how to read digital input values from the DIO Port0 using the Harp Behavior board (see hardware schematics below). Workflow Details Creates a connection with the Behavior board. The PortName property in the Behavior node needs to be set to the COM device on the computer. Filters the messages from the Behavior board that pertain DIO port inputs. Selects the DIO0 from the list of possible DIO inputs (see the output of the Parse node in 2). Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board has seven digital input channels: DIPort0, DIOPort0, DIPort1, DIOPort1, DIPort2, DIOPort2, and DI3. The maximum tolerable voltage at these ports is 5V. In this example, the board receives a digital input signal from a switch connected to DIOPort0. Since the DIOs inputs have a pullup resistor - signal is high when nothing is connected - when switched is pressed, the input signal goes low."
  },
  "workflows/HarpExamples/BehaviorBoard/DigitalInput/DigitalInput.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/DigitalInput/DigitalInput.html",
    "title": "Digital Input | CF.Bonsai",
    "keywords": "Digital Input Summary This example demonstrates how to get the digital input values from a switch using the Harp Behavior board (see hardware schematics below). Workflow Details Creates a subject node to send commands to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Filters event messages associated with the state of digital inputs. Demultiplexes the decimal values associated with the state of the digital ports into an array of bits, each indicating the state of a specific port. Converts the bit array from Mat to byte[]. Gets the fourth element of the byte array (as an integer value), which corresponds to the digital input port 3 (DI3). Enables the Behavior board to send out events associated with DI3. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board has four digital input channels: DIPort0, DIPort1, DIPort2, and DI3. The maximum tolerable voltage at these ports is 5V. In this example, the board receives a digital input signal from a switch connected to DI3."
  },
  "workflows/HarpExamples/BehaviorBoard/DigitalOutput/DigitalOutput.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/DigitalOutput/DigitalOutput.html",
    "title": "Digital Output | CF.Bonsai",
    "keywords": "Digital Output Summary This example demonstrates how to control the ON/OFF state of an LED using the digital output from the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Turns the LED ON when 'A' is pressed. Turns the LED OFF when 'S' is pressed Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can control four digital output ports: DO0, DO1, DO2, and DO3. The DOs output voltage is 5V. In this example, the board controls the ON/OFF state of an LED connected to DO0. A resistor of \\(200\\mathsf{\\Omega}\\) is used to drop the current passing through the LED and prevent it from burning."
  },
  "workflows/HarpExamples/BehaviorBoard/DigitalOutputPulse/DigitalOutputPulse.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/DigitalOutputPulse/DigitalOutputPulse.html",
    "title": "Digital Output Pulse | CF.Bonsai",
    "keywords": "Digital Output Pulse Summary This example demonstrates how to trigger a digital pulse, with a fixed duration, on a LED using the digital output from the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Enables triggering pulses in port DO0. Sets the pulse duration to 1000ms. Triggers the pulse whenever 'A' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can trigger pulses in seven digital output ports: DO0, DO1, DO2, DO3, DOPort0, DOPort1, DOPort2, and the LED current ports: Led0, Led1. The output voltage of these ports is 5V. In this example, the delivers a digital pulse to an LED connected to DO0. A resistor of \\(200\\mathsf{\\Omega}\\) is used to drop the current passing through the LED and prevent it from burning."
  },
  "workflows/HarpExamples/BehaviorBoard/LEDToggle/LEDToggle.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/LEDToggle/LEDToggle.html",
    "title": "LED Toggle | CF.Bonsai",
    "keywords": "LED Toggle Summary This example demonstrates how to control the brightness of a LED using the current driven ports in the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the maximum current to be sent to the LED as a precaution. Sets the actual current to be sent to the LED. Turns the LED ON when 'A' is pressed. Turns the LED OFF when 'S' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board has two current sources: Led0 and Led1. In this example, the board controls controls the brightness of an LED connected to Led0."
  },
  "workflows/HarpExamples/BehaviorBoard/LogAll/LogAll.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/LogAll/LogAll.html",
    "title": "Log All | CF.Bonsai",
    "keywords": "Log All Summary Const Workflow Details Const Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org)"
  },
  "workflows/HarpExamples/BehaviorBoard/LogSelected/LogSelected.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/LogSelected/LogSelected.html",
    "title": "Log Selected | CF.Bonsai",
    "keywords": "Log Selected Summary This example demonstrates how to log the events that control the ON/OFF state of a LED using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Filters all the messages from the Behavior board that set digital output ports to ON. Filters all the messages from the Behavior board that set digital output ports to OFF. Turns the LED ON when 'A' is pressed. Turns the LED OFF when 'S' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics All the messages to and from the Harp Behavior can be logged. In this example, only data relative setting and clearing of digital output ports is logged. CSV Conversion It's often desirable to convert the binary files that come out of the MessageWriter node into a human readable file. One way to do this is to convert them into CSV files through the Harp Convert To CSV GUI."
  },
  "workflows/HarpExamples/BehaviorBoard/NosePokeDetection/NosePokeDetection.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/NosePokeDetection/NosePokeDetection.html",
    "title": "Nose Poke Detection | CF.Bonsai",
    "keywords": "Nose Poke Detection Summary This example demonstrates how to detect a rodent nose poke using the Mice Poke peripheral for the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Reads the state of the nose poke. Filters the messages from the Behavior board that pertain the digital inputs. Selects the poke port DIPort0. Converts the output of 2. to Int. Outputs values only when the value of the specific poke port (DIPort0) has changed. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board has dedicated inputs for three nose pokes: DIPort0, DIPort1 and DIPort2. In this example, the board receives inputs from port DIPort0. TODO: Add schematics"
  },
  "workflows/HarpExamples/BehaviorBoard/NosePokeLEDToggle/NosePokeLEDToggle.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/NosePokeLEDToggle/NosePokeLEDToggle.html",
    "title": "Nose Poke LED Toggle | CF.Bonsai",
    "keywords": "Nose Poke LED Toggle Summary This example demonstrates how to toggle the built-in LED from the Mice Poke peripheral for the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Turns off the LED in the digital output port DOPort0. Toggles the LED whenever 'A' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can control LEDs for three nose pokes: DOPort0, DOPort1 and DOPort2. In this example, the board controls the LED in port DOPort0. TODO: Add schematics"
  },
  "workflows/HarpExamples/BehaviorBoard/PWMToggle/PWMToggle.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/PWMToggle/PWMToggle.html",
    "title": "PWM Toggle | CF.Bonsai",
    "keywords": "PWM Toggle Summary This example demonstrates how to control a PWM signal to drive the brightness of a LED using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the duty cycle of the PWM signal to 50%. Initiates the PWM signal. Sets the PWM frequency to 1Hz when 'A' is pressed. Sets the PWM frequency to 5Hz when 'S' is pressed. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can control four PWM sources in ports: DO0, DO1, DO2 and DO3. The DOs output voltage is 5V. In this example, the board controls the brightness of a LED connected to DO0. A resistor of \\(200\\mathsf{\\Omega}\\) is used to drop the current passing through the LED and prevent it from burning."
  },
  "workflows/HarpExamples/BehaviorBoard/QuadratureEncoder/QuadratureEncoder.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/QuadratureEncoder/QuadratureEncoder.html",
    "title": "Quadrature Encoder | CF.Bonsai",
    "keywords": "Quadrature Encoder Summary This example demonstrates how to obtain the position values of a quadrature encoder using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Filters the messages from the Behavior board that pertain analog inputs. Selects the Encoder from the list of possible analog outputs (see the output of the Parse node in 1.2). Resets the quadrature encoder counts such that the encoder starts at zero. Enables the quadrature encoder. Ensures that command messages are sent only when the device is ready. Requirements This example requires the following Bonsai packages: Harp - Behavior (from nuget.org) Schematics The Harp Behavior board can read the position value of one quadrature encoder connected to Port2. The encoder in the schematics is the ENC1J-D28-L00128L."
  },
  "workflows/HarpExamples/BehaviorBoard/README.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/README.html",
    "title": "CF.Bonsai Harp Behavior Examples | CF.Bonsai",
    "keywords": "CF.Bonsai Harp Behavior Examples Summary This folder provides a set of examples to deal with the different features of the HARP Behavior board. HARP Installation Before you can use HARP devices in Bonsai you need to install a few packages: Install HARP drivers and software here Install the HARP package for Bonsai. Go to Manage Packages In Package sources select nuget.org Search for 'HARP Behavior' Install the package"
  },
  "workflows/HarpExamples/BehaviorBoard/ServoMotorControl/ServoMotorControl.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/ServoMotorControl/ServoMotorControl.html",
    "title": "Servo Motor Control | CF.Bonsai",
    "keywords": "Servo Motor Control Summary This example demonstrates how to control a servo motor using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the period of the servo motor's PWM in microseconds. Normal servos use a period of \\(20000\\mathsf{\\mu s}\\). Enables the servo motor when 'A' is pressed. Disables the servo motor when 'S' is pressed. Sets the desired angle of the servo motor. Converts the angle into a PWM pulse width, which typically ranges between a minimum value of \\(1000\\mathsf{\\mu s}\\) and a maximum value of \\(2000\\mathsf{\\mu s}\\). Converts the pulse width into an integer value. Sets the pulse width property of the servo motor and emits a new event forward. Creates a new Harp message with the new pulse width. Requirements This example requires the following Bonsai packages: Harp - Behavior Schematics The Harp Behavior board can control two servo motors in ports DO2 and DO3. The DOs output voltage is 5V. In this example, the board controls controls the position of a servo motor connected to DO2."
  },
  "workflows/HarpExamples/BehaviorBoard/ServoMotorToggle/ServoMotorToggle.html": {
    "href": "workflows/HarpExamples/BehaviorBoard/ServoMotorToggle/ServoMotorToggle.html",
    "title": "Servo Motor Toggle | CF.Bonsai",
    "keywords": "Servo Motor Toggle Summary This example demonstrates how to toggle a servo motor between two positions using Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board and publishes all the events from the device. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the period of the servo motor's PWM in microseconds. Normal servos use a period of \\(20000\\mathsf{\\mu s}\\). Enables the servo motor. Sets the minimum position of the servo motor when 'A' is pressed.* Sets the maximum position of the servo motor when 'S' is pressed.* Ensures that command messages are sent only when the device is ready. *The angular position of servo motors is typically defined by the pulse width time of a PWM signal. This value typically ranges from \\(1000\\mathsf{\\mu s}\\) (minimum) and \\(2000\\mathsf{\\mu s}\\) (maximum). Requirements This example requires the following Bonsai packages: Harp - Behavior Schematics The Harp Behavior board can control two servo motors in ports DO2 and DO3. The DOs output voltage is 5V. In this example, the board controls controls the position of a servo motor connected to DO2."
  },
  "workflows/HarpExamples/Feeder/RewardDelivery/RewardDelivery.html": {
    "href": "workflows/HarpExamples/Feeder/RewardDelivery/RewardDelivery.html",
    "title": "Reward Delivery | CF.Bonsai",
    "keywords": "Reward Delivery Summary This example demonstrates how to give a reward with a feeder. An example of an automatic feeder can be found here. The feeders use the same board as the Harp SyringePump. For this example, it is assumed that the feeder is using a disk with 40 equally spaced reward positions. Workflow Details Initializes the needed variables/subjects (UpdateStep, StepNumber, NumberOfSteps). Establishes the commands to be sent to the SyringePump board and publishes all the events from the device. The PortName property in the SyringePump node needs to be set to the COM device on the computer. To create the subject node, right-click on the SyringePump node -> Create Source -> Behavior Subject, and name it accordingly. Sets the SyringePump protocol direction to Forward. Sets the number of steps of the SyringePump protocol. The number of steps changes according to 9. and 10. to compensate for the fact that the board doesn't accept non-integer number of steps. Sets the step period to 10 ms (default value). Sets the step mode to quarter-step. Feel free to try other step modes, but remember to change the number of steps accordingly if you intend to keep the same amount of rotation degrees. Ensures that command messages are sent only when the device is ready. Gives a reward when A is pressed. Enables the motor. Executes the SyringePump protocol. Disables the motor. Updates the StepNumber Behavior Subject every time a reward is given. If the current StepNumber is equal to 5 it updates to 1, otherwise it adds 1 to the current value. Updates the NumberOfSteps Behavior Subject (which in turn updates the protocol step count) according to the current StepNumber. If StepNumber is less than 4, the NumberOfSteps is set to 104, otherwise it is set to 103. Requirements This example requires the following Bonsai packages: Harp - SyringePump (from nuget.org) How to calculate the needed number of steps per reward In the Details section, the fact that the number of steps per protocol is either 103 or 104 seems arbitrary, but there's a reason for it. This section aims to address how one can calculate the needed number of steps to deliver consecutive rewards that are equally spaced in the circular mechanism. For the case presented above, we know that there are 40 possible reward positions. The angle that separates 2 consecutive rewards is given by: \\(\\frac{360\\degree}{40} = 9\\degree\\) So every time a SyringePump protocol is executed, the mechanism should advance \\(9\\degree\\). To convert this value to motor steps, one has to divide it by the amount of degrees that a motor step is equivalent to. For the feeder's motor, each motor step is equivalent to \\(1.8\\degree\\). However, the motor has an internal gear so that in order for the shaft to make a full rotation it's necessary that the motor fully rotates 5.18 times. With this in mind, it's now possible to calculate the number of full-steps needed for the shaft to move \\(9\\degree\\): \\(\\frac{9\\degree}{\\frac{1.8\\degree}{5.18}} = \\frac{9\\degree \\times 5.18}{1.8\\degree} = 25.9 \\text{ steps}\\) Then, since the stepper motor has different micro steps (or step modes), such has half-steps or quarter-steps, there's a need to multiple the previous result with the respective micro step multiplier. Full-step: x1 Half-step: x2 Quarter-step: x4 Eighth-step: x8 Sixteenth-step: x16 Since the example above uses quarter-step, we get: \\(25.9 \\times 4 = 103.6 \\text{ quarter-steps}\\) Finally, as mentioned before, it is not possible to execute SyringePump protocols with non-integer number of steps. If one decides to just round the result either up or down, it will cause a cumulative displacement error of the disk in the long term. For this example, this cumulative displacement error can be completely corrected by executing 2 protocols with 103 steps every 5 protocols and the remaining 3 out of 5 protocols with 104 steps (because \\(103.6 \\times 5 = 103 \\times 2 + 104 \\times 3 = 518 \\text{ steps}\\))."
  },
  "workflows/HarpExamples/Olfactometer/EndValveToggle/EndValveToggle.html": {
    "href": "workflows/HarpExamples/Olfactometer/EndValveToggle/EndValveToggle.html",
    "title": "End Valve Toggle | CF.Bonsai",
    "keywords": "End Valve Toggle Summary This example demonstrates how to configure the Harp Olfactometer to toggle the End valve using the Harp Olfactometer board (see hardware diagram below). Workflow Details Creates a subject node to send commands to the Olfactometer board and publishes all the events from the device. The PortName property in the Olfactometer node needs to be set to the COM device on the computer. To create the subject node, right-click on the Olfactometer node -> Create Source -> Behavior Subject, and name it accordingly. Filters event messages associated with the Channel 0 flow rate. Filters event messages associated with the Channel 3 flow rate. Filters event messages associated with the Channel 4 flow rate. Enables the Olfactometer flow by pressing the 'B' key. Disables the Olfactometer flow by pressing the 'E' key. Enables the End valve to be configured with hardware generated pulse. Configures the value (in milliseconds) of the End valve pulse. Selects the Channel 3 flow range (0-1000 ml/s). Sets the target flow rate for all the channels of the olfactometer. If they are not used they are configure with zero value. Ensures that command messages are sent only when the device is ready. Sets the state of the different valves and End valve to perform a 500 ms odor delivery through the End valve after 'A' key press. Odor valve 0 and valve 3 (used as auxiliary carrier) are enabled 2 seconds before the End valve toggle. End valve is enabled and will execute the pre-configured pulse. Odor valve 0 and valve 3 are disabled. Requirements This example requires the following Bonsai package: Harp.Olfactometer (from nuget.org) - make sure to select 'Include prerelease' Schematics The Harp Olfactometer supports up to 4 odor channels and 1 carrier line. When using an End valve, Channel 3 is used as an auxiliary carrier line. In this example Channel 0 (odor line) is configured with a 80 ml/min flow rate, Channel 3 (auxiliary carrier) with 800 ml/min and Channel 4 (carrier line) with 720 ml/min. The sum of Channel 0 and Channel 4 flows should match the value of Channel 3 in order to maintain the same flow rate at the output, whether odor is being presented or not. After 'A' key press the odor channel flow is enabled, goes through the correspondent vial, mixes with the auxiliary carrier line and is exhausted in the end valve during a time period before the End valve is toggled in order to stabilize the mixture. During this time, clean air is being delivered to the animal through the End valve. After that, the End valve toggles during 500 ms and the odorized air is delivered to the animal while the clean air is exhausted. Finally after the End valve toggling time, the Channel 0 and Channel 3 are disabled."
  },
  "workflows/HarpExamples/Olfactometer/OdorValveToggle/OdorValveToggle.html": {
    "href": "workflows/HarpExamples/Olfactometer/OdorValveToggle/OdorValveToggle.html",
    "title": "Odor Valve Toggle | CF.Bonsai",
    "keywords": "Odor Valve Toggle Summary This example demonstrates how to configure the Harp Olfactometer to toggle the Odor Valves using the Harp Olfactometer board (see hardware diagram below). Workflow Details Creates a subject node to send commands to the Olfactometer board and publishes all the events from the device. The PortName property in the Olfactometer node needs to be set to the COM device on the computer. To create the subject node, right-click on the Olfactometer node -> Create Source -> Behavior Subject, and name it accordingly. Filters event messages associated with the Channel 0 flow rate. Filters event messages associated with the Channel 1 flow rate. Filters event messages associated with the Channel 4 flow rate. Enables the Olfactometer flow by pressing the 'B' key. Disables the Olfactometer flow by pressing the 'E' key. Enables the valves to be configured with hardware generated pulse. Configures the value (in milliseconds) of the Odor valve 0 pulse. Configures the value (in milliseconds) of the Odor valve 1 pulse. Sets the target flow rate for all the channels of the olfactometer. If they are not used they are configure with zero value. Ensures that command messages are sent only when the device is ready. Sets the state of the different valves to perform a 500 ms odor delivery after 'A' key press. Odor valve 0 is enabled 2 seconds before the Odor valve 1 toggles. Odor valve 1 is enabled. Requirements This example requires the following Bonsai package: Harp.Olfactometer (from nuget.org) - make sure to select 'Include prerelease' Schematics The Harp Olfactometer supports up to 4 odor channels and 1 carrier line. In this example, Channel 0 (odor line) is configured with a 80 ml/min flow rate, Channel 1 (odor line) with 80 ml/min and Channel 4 (carrier line) with 720 ml/min. After 'A' key press the odor channel 0 flow is enabled, goes through the correspondent vial, mixes with the auxiliary carrier line and is delivered to the animal. The duration of the odor pulse is 500 ms. Then, 2 s after the enabling of odor channel 0, odor channel 1 is also enabled during 500 ms, mixed with the auxiliary carrier line and delivered to the animal."
  },
  "workflows/HarpExamples/SoundCard/PlayFrequency/PlayFrequency.html": {
    "href": "workflows/HarpExamples/SoundCard/PlayFrequency/PlayFrequency.html",
    "title": "PWM Toggle | CF.Bonsai",
    "keywords": "PWM Toggle Summary This example demonstrates how to control a PWM signal to drive the brightness of a LED using the Harp Behavior board (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Behavior board. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the Behavior node -> Create Source -> Behavior Subject, and name it accordingly. Sets the duty cycle of the PWM signal to 50%. Initiates the PWM signal. Sets the PWM frequency to 1Hz when 'A' is pressed. Sets the PWM frequency to 5Hz when 'A' is pressed. Ensures that command messages are sent only when the device is ready. Requirements Install Harp SoundCard (https://harp-tech.org/api/Harp.SoundCard.html) This example requires the following Bonsai packages: Harp - SoundCard (from nuget.org)"
  },
  "workflows/HarpExamples/SoundCard/PlaySound/PlaySound.html": {
    "href": "workflows/HarpExamples/SoundCard/PlaySound/PlaySound.html",
    "title": "Play Sound | CF.Bonsai",
    "keywords": "Play Sound Summary This example demonstrates how to play a .wav file using the Harp SoundCard board (see hardware schematics below). Workflow Details The Harp SoundCard board allows the user to upload wav files using its graphical user interface (see details here). Each file is linked to an index (2-31), which can be played by the sound card. Establishes the commands to be sent to the SoundCard board. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the SoundCard node -> Create Source -> Behavior Subject, and name it accordingly. Plays the sound stored at index 4, when 'A' is pressed. * Plays the sound stored at index 5, when 'S' is pressed. ** Ensures that command messages are sent only when the device is ready. * The example file loaded in index 4 can be found here ** The example file loaded in index 5 can be found here Requirements This example requires the following Bonsai packages: Harp - SoundCard (from nuget.org) Additionally, install the Harp SoundCard GUI in order to upload sounds to the SoundCard. Schematics The Harp SoundCard board has 2 RCA ports (one for the left channel and the other for the right one) which allow the device to connect to a Harp Audio Amplifier on each side which, in turn, connect to a speaker. Uploading sounds to the Harp SoundCard Install the Harp SoundCard GUI. Open the GUI. Then click on Launch. It is possible to generate pure tones and white noises or to load sounds from .wav or binary files. Either way, after tweaking with the configurations according to one's needs, click on the correct Generate button (for a sound loaded from a .wav - or binary - file, the button is names Load and Generate). The sound will be plotted in the figure at the bottom of the GUI. In the Interface with the Sound Card frame of the GUI, select the index (between 2 and 31) where the sound will be uploaded to in the device's memory. Then click on Create files and send to device. Optional: To play the sound, select the device's COM port and sound index in the bottom right corner of the GUI (above the plot) and hit the Play button. Mandatory: Party as hell to your recently uploaded sound! :D"
  },
  "workflows/HarpExamples/SoundCard/SoundHardwareTrigger/SoundHardwareTrigger.html": {
    "href": "workflows/HarpExamples/SoundCard/SoundHardwareTrigger/SoundHardwareTrigger.html",
    "title": "Play Sound | CF.Bonsai",
    "keywords": "Play Sound Summary This example demonstrates how to play a .wav file using the Harp SoundCard board from an external trigger given by the Harp Behavior (see hardware schematics below). Workflow Details The Harp SoundCard board allows the user to upload wav files using its graphical user interface (see details here????). Each file is linked to an index (0-31), which can be played by the sound card. Establishes the commands to be sent to the SoundCard board. The PortName property in the Behavior node needs to be set to the COM device on the computer. To create the subject node, right-click on the SoundCard node -> Create Source -> Behavior Subject, and name it accordingly. Plays the sound stored at index 4, when 'A' is pressed. * Plays the sound stored at index 5, when 'S' is pressed. ** Ensures that command messages are sent only when the device is ready. * The example file loaded in index 4 can be found here ** The example file loaded in index 5 can be found here Requirements This example requires the following Bonsai packages: Harp - SoundCard (from nuget.org) Additionally, install the Harp SoundCard GUI in order to upload sounds to the SoundCard. Schematics The Harp Sound Card"
  },
  "workflows/HarpExamples/SyringePump/CalibrationProtocol/CalibrationProtocol.html": {
    "href": "workflows/HarpExamples/SyringePump/CalibrationProtocol/CalibrationProtocol.html",
    "title": "Calibration Protocol | CF.Bonsai",
    "keywords": "Calibration Protocol Summary This article demonstrates how to calibrate the Harp SyringePump (see hardware schematics below), based on the protocol written by Naz Belkaya and Sofia Freitas, and with the contribution of Teresa Serradas Duarte. Procedure Define the Step Mode Set the desired step mode (step 1 of the Details section). Set the number of protocol repetitions (step 2.2 of the Details section). Prepare for the Calibration Gather the required materials: water, SyringePumps and 7 empty Eppendorf tubes. Weigh each empty Eppendorf tube and record the initial weights in the spreadsheet. Connect the Pumps Connect the pumps to the computer via the designated COM port (e.g., COM6). Ensure that each pump is identified separately. Verify that all pumps are communicating correctly. Initial Step Count Testing Start the calibration with a step count of 5. You will increase the step count by increments of 5 up to a maximum of 35 for testing. The step counts to be tested are: 5, 10, 15, 20, 25, 30, 35. Calibrate Each Pump with Different Step Counts For each of the 7 Eppendorf tubes: Assign a different step count from the list above. Adjust the step count in the Bonsai workflow and prepare the pump accordingly. Run the Bonsai workflow. Record Post-Dispensing Weights After completing the steps above for each tube, weigh the tubes again. Record the post-filling weights in the spreadsheet alongside the corresponding step count. Curve Fitting and Data Analysis Use the recorded data (step counts and corresponding water weights) to fit the curve (Excel, Python, MATLAB). Final Step Using the results, identify the optimal number of steps for dispensing the desired amount of liquid for your experiment or setup. Note It's expected that the calibration for syringes with equal sections give similar results, because since a motor step corresponds to a linear movement perpendicular to the syringe section, the mass of water dispensed is proportional to the syringe section for a given step mode-step count combination. Mass-to-Volume Water Conversion Since we want the relation between the number of steps and the volume of water dispensed during the execution of a single protocol, we need to convert the mass of water measured into volume, taking into account the \\(n\\) repetitions of the protocol: \\(V (\\mu\\text{L}) = \\frac{m (\\text{g})}{\\text{number of repetitions} \\times 10^{-3} (\\text{g/}\\mu\\text{L})}\\) where \\(V\\) is the volume of water and \\(m\\) is the corresponding mass. Bonsai Workflow Details Initializes the Harp SyringePump and configures the protocol to be used (identical to what is done in the Create and Execute Protocol example). Please set the PortName, ProtocolStepCount and the StepMode properties to be used in the protocol before starting the workflow. Executes the protocol defined in step 1. Enables the motor so that the protocol can be executed. This is where the protocol is actually executed \\(n\\) times so that the calibration is done accurately. Set the Count (number of repetitions) and DelayTime properties adequately before starting the workflow. The DelayTime should be greater than the time it takes for the SyringePump to execute a protocol, which is given by \\(\\text{step period} \\times \\text{step count}\\) (The default \\(\\text{step period}\\) is 10 ms). Read the Protocol SelectMany section to see how it's implemented. Disables the motor so that the controller doesn't heat up when it's not being used. Protocol SelectMany Starts the protocol defined in the step 1 of the Details section. Delays the data stream so that the protocol isn't stopped before it finishes. Beware that for the defined protocol the 2-second delay is enough, but it might not be enough for other protocols. This delay must be adapted according to the protocol used, as mentioned in the step 2 of the Details section. Stops the protocol. Repeats this workflow \\(n\\) times and returns only the event from the \\(n\\)-th repetition. Requirements This example requires: An up-to-date version of the SyringePump firmware. This example used the fw0.6-harp1.6. To upload the new firmware double-click on the SyringePump Device node in Bonsai and follow the instructions. The installation of the Bonsai package Harp - SyringePump (from nuget.org). It might also be useful to download the SyringePump GUI."
  },
  "workflows/HarpExamples/SyringePump/CreateAndExecuteProtocol/CreateAndExecuteProtocol.html": {
    "href": "workflows/HarpExamples/SyringePump/CreateAndExecuteProtocol/CreateAndExecuteProtocol.html",
    "title": "Create and Execute Protocol | CF.Bonsai",
    "keywords": "Create and Execute Protocol Summary This example demonstrates how to create and execute a reward delivery protocol using the Harp SyringePump (see hardware schematics below). Workflow Details Establishes the commands to be sent to the Harp SyringePump and publishes all the events from the device. The PortName property in the SyringePump node needs to be set to the COM device on the computer. To create the subject node, right-click on the SyringePump node -> Create Source -> Behavior Subject, and name it accordingly. Defines the protocol to be used. Sets the protocol direction. Sets the number of steps of the protocol. Sets the period of each step of the protocol. Sets the microstep used in the protocol (full step, half step,...). Smaller microsteps usually mean smoother motor movements. Ensures that command messages are sent only when the device is ready. Executes the protocol defined in steps 2-5 when A is pressed. Enables the motor so that the protocol can be executed. This is where the protocol is actually executed. Delays the data stream so that the motor isn't disabled before the protocol finishes. Beware that for the defined protocol the 1-second delay is enough, but it might not be enough for other protocols. This delay must be adapted according to the protocol used. Disables the motor so that the controller doesn't heat up when it's not being used. Requirements This example requires: An up-to-date version of the SyringePump firmware. This example used the fw0.6-harp1.6. To upload the new firmware double-click on the SyringePump Device node in Bonsai and follow the instructions. The installation of the Bonsai package Harp - SyringePump (from nuget.org). It might also be useful to download the SyringePump GUI. Schematics In this example, the Harp SyringePump controls a stepper motor."
  },
  "workflows/HarpExamples/SyringePump/ToggleMicroSteps/ToggleMicroSteps.html": {
    "href": "workflows/HarpExamples/SyringePump/ToggleMicroSteps/ToggleMicroSteps.html",
    "title": "Toggle Micro Steps | CF.Bonsai",
    "keywords": "Toggle Micro Steps Summary This example demonstrates how to toggle micro steps using the Harp SyringePump board (see hardware schematics below). Workflow Details Requirements This example requires: An up-to-date version of the SyringePump firmware. This example used the fw0.6-harp1.6. To upload the new firmware double-click on the SyringePump Device node in Bonsai and follow the instructions. The installation of the Bonsai package Harp - SyringePump (from nuget.org) It might also be useful to download the SyringePump GUI."
  },
  "workflows/HarpExamples/SyringePump/ToggleMultipleSteps/ToggleMultipleSteps.html": {
    "href": "workflows/HarpExamples/SyringePump/ToggleMultipleSteps/ToggleMultipleSteps.html",
    "title": "Toggle Multiple Steps | CF.Bonsai",
    "keywords": "Toggle Multiple Steps Summary This example demonstrates how to toggle multiple steps using the Harp SyringePump board (see hardware schematics below). Workflow Details Requirements This example requires: An up-to-date version of the SyringePump firmware. This example used the fw0.6-harp1.6. To upload the new firmware double-click on the SyringePump Device node in Bonsai and follow the instructions. The installation of the Bonsai package Harp - SyringePump (from nuget.org). It might also be useful to download the SyringePump GUI. Schematics In this example, the Harp SyringePump controls a stepper motor."
  },
  "workflows/HarpExamples/SyringePump/ToggleSingleSteps/ToggleSingleSteps.html": {
    "href": "workflows/HarpExamples/SyringePump/ToggleSingleSteps/ToggleSingleSteps.html",
    "title": "Toggle Single Steps | CF.Bonsai",
    "keywords": "Toggle Single Steps Summary This example demonstrates how to toggle single steps using the Harp SyringePump board (see hardware schematics below). Workflow Details Requirements This example requires: An up-to-date version of the SyringePump firmware. This example used the fw0.6-harp1.6. To upload the new firmware double-click on the SyringePump Device node in Bonsai and follow the instructions. The installation of the Bonsai package Harp - SyringePump (from nuget.org) It might also be useful to download the SyringePump GUI."
  },
  "workflows/NeuroExamples/SaveExperimentalParameters/testing.html": {
    "href": "workflows/NeuroExamples/SaveExperimentalParameters/testing.html",
    "title": "Bananas! | CF.Bonsai",
    "keywords": "Bananas! here we have a banana banana: yellow banana: green banana: brown banana: red banana: purple And this concludes the banana test."
  },
  "workflows/NeuroExamples/TrialBasedSkeleton/TrialBasedSkeleton.html": {
    "href": "workflows/NeuroExamples/TrialBasedSkeleton/TrialBasedSkeleton.html",
    "title": "Trial-Based Sesssion | CF.Bonsai",
    "keywords": "Trial-Based Sesssion Under construction..."
  },
  "workflows/ReactiveExamples/Average/Average.html": {
    "href": "workflows/ReactiveExamples/Average/Average.html",
    "title": "Average | CF.Bonsai",
    "keywords": "Average Summary This example demonstrates how to get the average of elements generated by a stream once it has terminated using the Average operator. Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Averages all the values generaged by the stream. Prevents Bonsai from terminating once the five events have been generated, and in doing so, it allows the user to visualize the output of the Average node. Visualization Visualize the output of both the Timer and Average nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/BehaviorSubject/BehaviorSubject.html": {
    "href": "workflows/ReactiveExamples/BehaviorSubject/BehaviorSubject.html",
    "title": "BehaviorSubject | CF.Bonsai",
    "keywords": "BehaviorSubject Summary This example demonstrates how to get data from a stream that is already running using the BehaviorSubject node. The subscribed subject only receives the last event generated before the subscriptions as well as all of those generated subsequently. Workflow Details Creates a Subject, named MySubject, with the values of a counter that starts with value 0 gets incremented every 2s. Subscribes MySubject 1s after the start of the program. Double-click on this node to visualize its content and compare it with that of the Timer node. You should see that the first value of the Timer (value 0) is received by the DelaySubscription even though the subscription was done after the value has been emitted. All subsequent values emitted by the Timer will reach the DelaySubscription node. Visualization Vizualize the node outputs using the ObjectTextVizualizer with expanded windows to better compare their contents. Follow up You can compare this with other Subject types: PublishSubject and ReplaySubject."
  },
  "workflows/ReactiveExamples/Concat/Concat.html": {
    "href": "workflows/ReactiveExamples/Concat/Concat.html",
    "title": "Concat | CF.Bonsai",
    "keywords": "Concat Summary This example demonstrates how to unpack the elements of an array using Concat Workflow Details Gets the directories under the C:\\ drive (change the Path property for other parent directories). Converts the string array with the directories in (1) to individual strings, each containing the path to one of the directories. Prevents Bonsai from terminating when all the elements of the array have been emitted. Visualization Visualize the output of the GetDirectories and Concat nodes using ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/Count/Count.html": {
    "href": "workflows/ReactiveExamples/Count/Count.html",
    "title": "Count | CF.Bonsai",
    "keywords": "Count Summary This example demonstrates how to get number of elements generated by a stream once it has terminated using the Count operator. Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Counts the number of events generaged by the stream. Prevents Bonsai from terminating once the five events have been generated, and in doing so, it allows the user to visualize the output of the Count node. Visualization Visualize the output of both the Timer and Count nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/CreateObservable/CreateObservable.html": {
    "href": "workflows/ReactiveExamples/CreateObservable/CreateObservable.html",
    "title": "CreateObservable | CF.Bonsai",
    "keywords": "CreateObservable Summary This example demonstrates how the behavior of the CreateObservable node is modified when subscribed by the high-level operators Merge, Concat, or Switch nodes Workflow Details The behavior of the CreateObservable node is a bit special, in the sense that it needs to be subscribed by a subsequent higher-level operator in order to run its internal workflow. In this example, the workflow under the CreateObservable nodes is the same for the three branches, and every instance of the CreateObservable generates a counter (Timer) that starts at 0 and terminates at 4 (Take), when it stops and closes the sequence (see workflow below). In this example, we show three ways in which the node can be subscribed, and how each way changes the subscription schedule. Generates a notification whenever the 'A' key is pressed and passes it to MySubject. Initiates a counter asynchronously everytime MySubject gets a notification. The counter is subscribed by a Merge node. Initiates a counter asynchronously everytime MySubject gets a notification. The counter is subscribed by a Concat node. Initiates a counter asynchronously everytime MySubject gets a notification. The counter is subscribed by a Switch node. CreateObservable Visualization Visualize the Merge, Concat and Switch nodes using the TimeSeriesVisualizer and their behavior whenever 'A' is pressed. You will see that if you only press the key once in every 5 seconds, the nodes behave the same. This is because each branch will have only one active instance of CreateObservable running. However, if you press 'A' twice within a ~2 seconds interval, you will generate two active instances of CreateObservable, in each branch, running asynchronously from each other. This will produce very different results when followed by Merge, Concat and Switch: The Merge node will output the latest value generated by either concurrent instances of CreateObservable. In doing this, the pair of nodes CreateObservable and Merge will behave similarly to a SelectMany node, which is implicitly followed by a Merge operation. The Concat node will only generate values from the second instance, only after first one has terminated, i.e. it will show first the five values generated by the first counter, followed by the five values generated by the second. The Switch node will show the values of the first counter only until the second starts. Once this happens the first counter is closed and only the second one will normally produce its notifications. Note: To verify that the inner workflow of the CreateObservable does not run without a subsequent subscription by either of the three higher-level operators, you can remove one of this operators from one of the branches, go inside the CreateObservable workflow, and visualize the notifications generated by the Timer node when your program is running. If you do this, you will see that no element will be generated in response to an 'A' key press."
  },
  "workflows/ReactiveExamples/Delay/Delay.html": {
    "href": "workflows/ReactiveExamples/Delay/Delay.html",
    "title": "Delay | CF.Bonsai",
    "keywords": "Delay Summary This example demonstrates how to delay the propagation of an event using the Delay operator. Here, the notification of a key press is delayed by one second. Workflow Details Generates an event whenever a key is pressed. Delays the propagation of the key pressed by one second. Visualization Compare the outputs of the KeyDown and Delay nodes using ObjectTextVisualizer enlarged, such that multiple events can be observed in each."
  },
  "workflows/ReactiveExamples/ElementIndex/ElementIndex.html": {
    "href": "workflows/ReactiveExamples/ElementIndex/ElementIndex.html",
    "title": "ElementIndex | CF.Bonsai",
    "keywords": "ElementIndex Summary This example demonstrates how to get the index of each event generated in a stream. In Bonsai this is equivalent to the number of current elements generated in a stream subtracted by 1. Workflow Details Generates an event every 100ms. Computes the index of the current event. Outputs the index of the current event. To obtain this node, right-click over the ElementIndex node and select Ouptut -> Index."
  },
  "workflows/ReactiveExamples/Max/Max.html": {
    "href": "workflows/ReactiveExamples/Max/Max.html",
    "title": "Max | CF.Bonsai",
    "keywords": "Max Summary This example demonstrates how the maximum value generated by a stream once it has terminated using the Max operator. Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Emits the maximum value generaged by the stream. Prevents Bonsai from terminating once the five events have been generated, and in doing so, it allows the user to visualize the output of the Max node. Visualization Visualize the output of both the Timer and Max nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/Merge/Merge.html": {
    "href": "workflows/ReactiveExamples/Merge/Merge.html",
    "title": "Merge | CF.Bonsai",
    "keywords": "Merge Summary This example demonstrates how to merge events from two independent streams using the Merge operator. In this case, presses in either 'A' or 'S' keys are propagated. Workflow Details Generates an event whenever 'A' is pressed. Generates an event whenever 'S' is pressed. Propagates all the input events in the order they are received. Note: The Merge node requires all its input streams to emit events of the same datatype. Visualization Visualize the output of the Merge node using ObjectTextVisualized enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/Min/Min.html": {
    "href": "workflows/ReactiveExamples/Min/Min.html",
    "title": "Min | CF.Bonsai",
    "keywords": "Min Summary This example demonstrates how the minimum value generated by a stream once it has terminated using the Min operator. Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Emits the minimum value generaged by the stream. Prevents Bonsai from terminating once the five events have been generated, and in doing so, it allows the user to visualize the output of the Min node. Visualization Visualize the output of both the Timer and Min nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/PublishSubject/PublishSubject.html": {
    "href": "workflows/ReactiveExamples/PublishSubject/PublishSubject.html",
    "title": "PublishSubject | CF.Bonsai",
    "keywords": "PublishSubject Summary This example demonstrates how to get data from a stream that is already running using the PublishSubject node. The subscribed subject only receives events that are generated after subscription. Workflow Details Creates a Subject, named MySubject, with the values of a counter that starts with value 0 gets incremented every 0.2s. Subscribes MySubject 1s after the start of the program. Double-click on this node to visualize its content and compare it with that of the Timer node. You should see that the first value of the Timer (value 0) is skipped by the DelaySubscription because the subject subscription occurs after that value has been emitted. All subsequent values emitted by the Timer will reach the DelaySubscription node. Visualization Vizualize the node outputs using the ObjectTextVizualizer with expanded windows to better compare their contents. Follow up You can compare this with other Subject types: BehaviorSubject and ReplaySubject."
  },
  "workflows/ReactiveExamples/ReplaySubject/ReplaySubject.html": {
    "href": "workflows/ReactiveExamples/ReplaySubject/ReplaySubject.html",
    "title": "ReplaySubject | CF.Bonsai",
    "keywords": "ReplaySubject Summary This example demonstrates how to get all the data from a stream that is already running, including values that were emited before we subscribed to the stream, using the ReplaySubject node. Workflow Details Creates a ReplaySubject, named MySubject, with the values of a counter that starts with value 0 gets incremented every 0.2s. Subscribes MySubject when 'A' is pressed. Double-click on this node to visualize its content and compare it with that of the Timer node. You should see that the when 'A' is pressed, all the values generated by the Timer node will appear in the SubscribeWhen node, including those that were generated before the keypress. Visualization Vizualize the node outputs using the ObjectTextVizualizer with an expanded window for each node to be able to better compare their contents. Follow up You can compare this with other Subject types: PublishSubject and BehaviorSubject."
  },
  "workflows/ReactiveExamples/SelectMany/SelectMany.html": {
    "href": "workflows/ReactiveExamples/SelectMany/SelectMany.html",
    "title": "SelectMany | CF.Bonsai",
    "keywords": "SelectMany Summary This example demonstrates how segment a stream of data into windows of 10 elements, and for each window, create a file with the elements in it using SelectMany Workflow Details Generates a counter that starts at 0 and gets incremented every 100ms. Creates windows of 10 consecutive elements. Allows a maximum of 5 windows to be created (in case the program does not terminate before that). Creates a file, for each window received, with the elements of each window. Visualization Save the workflow before running it; the files generated will be saved in the same directory as the workflow. Visualize the Timer, WindowCount and SelectMany nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out. Note: The SelectMany node in (4) will output the same elements as those generated by the Timer node in (1). However, it has done so only after those elements have been packed into windows of 10 elements in (2), and unpacked back inside the SelectMany node to be stored in different files. For every window received, SelectMany creates a separate, asynchronous, and independent process inside which it implicitely unpacks the content of the window in the Source node and, in this example, it explicitely saves it into a file (see workflow inside SelectMany node)."
  },
  "workflows/ReactiveExamples/Skip/Skip.html": {
    "href": "workflows/ReactiveExamples/Skip/Skip.html",
    "title": "Skip | CF.Bonsai",
    "keywords": "Skip Summary This example demonstrates how to control the beginning of a stream using the Skip operator. Here, values are propagated only after 5 events have been received. Workflow Details Generates an event every second. Prevents the propagation of the first 5 events, and starts propagating after. Visualization Compare the output of the Timer node with that of the Skip node. Use ObjectTextVisualizer enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/SkipUntil/SkipUntil.html": {
    "href": "workflows/ReactiveExamples/SkipUntil/SkipUntil.html",
    "title": "SkipUntil | CF.Bonsai",
    "keywords": "SkipUntil Summary This example demonstrates how to control the beginning of a stream using the SkipUntil operator. Here, values are propagated only after a key has been pressed. Workflow Details Generates an event every second. Holds the propagation of events until the 'S' key is pressed; it starts propagating after. Visualization Compare the output of the Timer node with that of the SkipUntil node. Use ObjectTextVisualizer enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/Sum/Sum.html": {
    "href": "workflows/ReactiveExamples/Sum/Sum.html",
    "title": "Sum | CF.Bonsai",
    "keywords": "Sum Summary This example demonstrates how to get number of elements generated by a stream once it has terminated using the Sum operator. Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Calulates the sum of all the values generated by the stream. Prevents Bonsai from terminating once the five events have been generated, and in doing so, it allows the user to visualize the output of the Sum node. Visualization Visualize the output of both the Timer and Sum nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/Take/Take.html": {
    "href": "workflows/ReactiveExamples/Take/Take.html",
    "title": "Take | CF.Bonsai",
    "keywords": "Take Summary This example demonstrates how to control the end of a stream using the Take operator. Here, the workflow terminates after 5 events generated by a Timer. Workflow Details Generates an event every second. Propagates the first 5 event, and emits an OnComplete message that terminates the preceding workflow. Terminates the main workflow when OnComplete message is received. Visualization Visualize the output of the Take node using ObjectTextVisualizer enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/TakeUntil/TakeUntil.html": {
    "href": "workflows/ReactiveExamples/TakeUntil/TakeUntil.html",
    "title": "TakeUntil | CF.Bonsai",
    "keywords": "TakeUntil Summary This example demonstrates how to control the end of a stream using the TakeUntil operator. Here, the workflow terminates after a key has been pressed. Workflow Details Generates an event every second. Propagates the events generated by the Timer until the 'S' key is pressed; when this happens, an OnComplete message is emited by the TakeUntil that terminates the preceding workflow. Terminates the main workflow when OnComplete message is received. Visualization Visualize the output of the TakeUntil node using ObjectTextVisualized enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/TimeInterval/TimeInterval.html": {
    "href": "workflows/ReactiveExamples/TimeInterval/TimeInterval.html",
    "title": "TimeInterval | CF.Bonsai",
    "keywords": "TimeInterval Summary This example demonstrates how to get the time interval between two consecutive events in a stream using the TimeInterval node. Workflow Details Generates an event every 100ms. Computes the time interval between events. Outputs the time interval in milliseconds between events. To obtain this node, right-click over the TimeInterval node select Ouptut -> Interval -> Total Milliseconds."
  },
  "workflows/ReactiveExamples/ToArray/ToArray.html": {
    "href": "workflows/ReactiveExamples/ToArray/ToArray.html",
    "title": "ToArray | CF.Bonsai",
    "keywords": "ToArray Summary This example demonstrates how to pack the elements of a stream into an array, once the stream terminates using ToArray Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Packs the 5 elements generated into an array. Gets the first element of the array (index=0). Gets the last element of the array (index=4). Prevents Bonsai from terminating when all the elements of the array have been emitted. Visualization Visualize the output of the Timer, ToArray and Index nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/ToList/ToList.html": {
    "href": "workflows/ReactiveExamples/ToList/ToList.html",
    "title": "ToList | CF.Bonsai",
    "keywords": "ToList Summary This example demonstrates how to pack the elements of a stream into a list, once the stream terminates using ToList Workflow Details Generates a counter that starts at 0 and gets incremented every 200ms. Terminates the stream once 5 events have been generated. Packs the 5 elements generated into a list. Gets the first element of the list (index=0). Gets the last element of the list (index=4). Prevents Bonsai from terminating when all the elements of the list have been emitted. Visualization Visualize the output of the Timer, ToList and Index nodes using the ObjectTextVisualizer enlarged, such that all the elements generated by each node can be observed. Also, make the visualizers are all open at the start of the program so that no element is left out."
  },
  "workflows/ReactiveExamples/WindowTrigger/WindowTrigger.html": {
    "href": "workflows/ReactiveExamples/WindowTrigger/WindowTrigger.html",
    "title": "WindowTrigger | CF.Bonsai",
    "keywords": "WindowTrigger Summary This example demonstrates how to create a new video, with a fixed number of frames, whenever a key is pressed, using the WindowTrigger operator. Workflow Details Captures the frames of a camera. Emits a signal every time the key 'A' is pressed. Creates a window containing 100 frames whenever 'A' is pressed. Unpacks the content of each window and creates a video file with the 100 frames for every window received. Visualization Visualize the output of the CameraCapture node and the SaveVideos node using IplImageVisualizer. Compare the outputs of each whenever the key 'A' is pressed. If you don't have a camera, you can substitute the CameraCapture node by a FileCapture node and open a video on your computer."
  },
  "workflows/ReactiveExamples/WithLatestFrom/WithLatestFrom.html": {
    "href": "workflows/ReactiveExamples/WithLatestFrom/WithLatestFrom.html",
    "title": "WithLatestFrom | CF.Bonsai",
    "keywords": "WithLatestFrom Summary This example demonstrates how to sample the latest values of a Timer sequence whenever a key is pressed. Workflow Details Generates an event whenever a key is pressed. Generates the next element of a counter every second. Pairs every key pressed with the current value of the Timer. Propagates Timer values that have been paired with the key presses in 3. Visualization Compare the output of the Timer node with that of the Item2 node. Use ObjectTextVisualizer enlarged, such that multiple events can be observed."
  },
  "workflows/ReactiveExamples/Zip/Zip.html": {
    "href": "workflows/ReactiveExamples/Zip/Zip.html",
    "title": "Zip | CF.Bonsai",
    "keywords": "Zip Summary This example demonstrates how to combine two streams using the Zip operator. This operator pairs events from multiple streams whenever they have all produced a value. Here, we pair the last two keypresses. Workflow Details Generates an event whenver a key is pressed. Skips the first key pressed. Creates a pair of values, a Tupple, with the current and the last keys pressed. Note: Because the Zip node pairs events only when all streams have emited a new value, the first event generated directly from the KeyDown in the first stream will be held until an event is produced by the Skip node in the second stream. This will happen only when a second key is pressed. Once this happens an event is propagated on the Skip node, and a pair can then be formed with the previous key press on the first stream (the one being held), and the current key pressed on the second stream. Visualization Visualize the output of the KeyPress, Skip and Zip nodes using ObjectTextVisualized enlarged, such that multiple events can be observed in each."
  },
  "workflows/Tutorials/Combinators/Combinators.html": {
    "href": "workflows/Tutorials/Combinators/Combinators.html",
    "title": "| CF.Bonsai",
    "keywords": "Combinators tutorial 0. Reactive Combinators Solution Pair a Timer (Period=1s) and an Int (Value=2), to three different combinators concurrently (i.e. in the same workflow): Zip, CombineLatest, WithLatestFrom. Use the Timer as the first input and the Int as the second input to all combinators, and analyze the output of the combinators. What do you see? Take your time to think about it. Does the behavior match the description of the combinators? Switch the order of the nodes in (11) such that the Int is now the first input and the Timer the second. Before you run your code, write down the output you expect for each of the combinators. Do your predictions match the real outcomes? Tip: You can drag the second element into the first element while pressing Alt. Visualize the coordinates of your mouse position using the ObjectTextVisualizer, and save them into a CSV file. Open the file in Notepad? Do you understand everything you see? Tip: MouseMove, CSVWriter Timestamp the mouse coordinates and add them to another CSV file. Can you open the text file and see the values inside? Tip: Timestamp Substitute the Timestamp node by the ElementIndex node in the previous example and add them to another CSV file. Can you interpret the output of the CSV file? Visualize the audio input from your microphone in the MatVisualizer. Try whistling"
  },
  "workflows/Tutorials/Subjects/Tracking.html": {
    "href": "workflows/Tutorials/Subjects/Tracking.html",
    "title": "| CF.Bonsai",
    "keywords": "Tutorial test Tracking Solution"
  },
  "workflows/Tutorials/Tracking/Tracking.html": {
    "href": "workflows/Tutorials/Tracking/Tracking.html",
    "title": "| CF.Bonsai",
    "keywords": "Tracking an object Tracking consists of identifying the position of one or several objects in time. In this tutorial we will divide this process in two stages: Segmentation. A pre-processing stage where we identify the pixels that belong to the object(s). This typically involves setting a mask where the pixels of interest are set to 1, while the others are set to 0. Tracking. This process consists of getting the actual coordinates of the objects of interest in the image. Typically this involves estimating the centroid, but other types of information, such as orientation, or size, can also usually be obtained. Here, we will learn different basic strategies to segment and track a single object of interest in a video. We will use Bonsai to demonstrate how each strategy can be implemented. You can use these two videos as examples: a grayscale video of a fly and a coloured HexBug in an arena. If you are interested in multi-object tracking, you can experiment with a grayscale video of 5 flies. Segmentation: Thresholding The first, and possibly the simplest, method for achieving segmentation is simple thresholding. Here, we use a color-based threshold performed in three different color spaces: BGR (Blue Green and Red) - We define for each color channel a range of acceptable values; pixels inside the ranges in all the colors are accepted (value 1), and pixels outside of that range are rejected (value 0). HSV (Hue, Saturation and Value) - The pixels are first converted to HSV and only thresholded after. Unlike the BGR color-space, the HSV encodes color in a single dimension - the Hue. Grayscale. The pixels are first converted to Grayscale and the subsequent thresholding requires only setting the lower and upper bounds of ilumination (ie. a single dimension) Notes: The Grayscale thresholding is the simplest method since one only has to segment in one dimension. If the contrast between your object and the background is strong enough this is usually a well suited method. It is also the only thresholding option to segment images from black and white cameras. If you need to rely on color for the segmentation then the HSV tends to be the method of choice. Since the color is well preserved in the Hue dimension across different light conditions, this color space is much more robust to changes in light intensity. Segmentation: Background subtraction Another set of methods widely used for segmentation is background subtraction, where we first estimate the background, and then subtract it to every frame of our video. Background segmentation is typically used with grayscale images. There are a number of ways to estimate the background; here we will look at three alternatives: First frame - Takes the first frame from the video as background and subtracts it to all the other frames. This method implies that the background is taken without the object of interest present in the image. Pixel extrema - Takes a block of frames, typically big enough to allow the object of interest to have moved, and it collects the brightest (or the darkest) intensity for each pixel during this interval. The background is then formed by the set of lowest or highest values for each pixel (see Guilbeault et al, 2021). A variant of this algorithm is to take, for each pixel, the median (or other percentile value) intensity across a portion of entire video. Adaptive background - Takes an moving average of the last N last frames and uses it as the background image. This image is then subtracted and thresholded. Notes The first method is rather rudimentary and relies heavily on the first frame being a good representative of the actual pixel values of the background across the entire video. Small changes in light intensity can destroy . It has the disadvantage of requiring image data with and without the object of interest. The second method computes the background wihout requiring an explicit background image. It is quite robust and in practice very useful. Nonetheless, it still relies on a relatively stable illumination across the entire video. More fundamentally, it also relies heavily on the object to appear relatively homogeneous; if the object is composed of dark and light areas then the background estimation can become compromised. You can see this by testing the second method on the Hexbug video. The third method, because of its adaptive nature, is usefull when the illumination conditions (or the actual background) are not static across the video. However, it is often difficult to set parameters that are robust across all the frames in a very dynamic video. Also, it tends to capture parts of the background close to the object as a part of the object itself. It also fails to identify the object when it is static. Try it yourself and test it with the Hexbug video. Segmentation: Temporal subtraction For the sake of completness, we can also simply subtract consecutive frames. If all that is chaning in the video is the position of the object of interest, we can assume that any meanigfull changes in pixel intensities occur where (and when) the object is moving. Like the third method above, this method fails to identify the object when it is not moving. In addition, due to the nature of the method, it tends to capture the contours of the object, rather than the full object. Tracking Once the object have been segmented from the background, we perform a stereotyped number of operations to extract the location of its centroid: Identify countours: Identify sets of thresholded pixels that are adjacent to each other. Here we can accept and reject countours based on their minimum and/or maximum area. Calculate contour properties: Compute basic properties of the contours identified such as centroid, area, or orientation. Select object contour: Select among all the available contours the one that belongs to our object of interest. Commonly this will be the largest contour of all. Extract the centroid: Select the centroid for visualization among the possible outputs of the selected countour."
  },
  "workflows/Tutorials/VirtualReality/VirtualReality.html": {
    "href": "workflows/Tutorials/VirtualReality/VirtualReality.html",
    "title": "Virtual Reality Turorial | CF.Bonsai",
    "keywords": "Virtual Reality Turorial In this tutorial, you’ll build a complete virtual reality (VR) system in Bonsai, allowing an agent—whether a fly, a fish, or a mouse—to freely explore a 3D environment. The scene is projected onto a 220º cylindrical display surrounding the agent, with two mirrors used to create an immersive panoramic view. Step by step, you’ll learn how to render the environment from the agent’s perspective and generate the images that accurately replicate what the agent is supposed to see when displayed from a projector (Fig.1). Fig.1: Schematics of the projected image into the cylindrical canvas surrounding the real agent with the aid of two mirrors. Getting started Setting up This tutorial provides Bonsai programs that you can copy and run directly in your Bonsai environment. Before running the examples, ensure that the necessary packages are installed. To quickly set up a working Bonsai environment, download the this ZIP file, unzip it to a directory of your choice, go to the directory bonsai and run setup.cmd. This will download all required packages and create a local Bonsai executable. To run the examples described here. You can simply run this executable, copy the example from this page, and paste it in Bonsai. Alternatively, you can run the local Bonsai executable, and load the examples provided in the ZIP file. The ZIP file also contains Shaders and Arena folders with the files used to create and render the 3D environment. These files will be explained in detail throughout the tutorial. Shaders graphics library Bonsai communicates with the graphics card using the Shaders library, along with the BonVision library (which is essentially an extension of Shaders, providing additional shader functions). These libraries allow Bonsai to create and render VR environments, offering operators for graphics rendering and dynamic control of OpenGL shader stages directly within Bonsai’s programming language. The VR problem At its core, the VR problem can be summarized as determining the color of each pixel in an image that the agent sees, so that the agent experiences the illusion of being immersed and moving within a 3D environment. To implement virtual reality worlds in Bonsai — and in VR systems more generally — three key aspects must be addressed: Spatial relationships: Defining how the agent’s current position relates to the positions of all objects in the 3D environment. Pixel color computation: Calculating the color of each pixel that forms the agent’s current view. Display mapping: Ensuring those pixel colors are correctly projected onto the physical display to create a coherent visual experience. In this tutorial, we will create a cylindrical VR projection spanning [-110º, 110º] around the agent. We will create three views (as shown the image above). The frontal view is projected directly onto the front of the cylinder, covering [-45º, 45º] (shown as the blue arc). Side views are projected with the help of mirrors placed on each side of the arena: the left mirror (green) covers [-110º, -45º], and the right mirror covers [45º, 110º]. Note that the use of mirrors implies a reversal of the projected side-view images, as the reflection flips the visual content. This must be accounted for in the rendering pipeline to ensure the agent perceives a coherent and continuous panoramic view. With this arrangement, the agent experiences full immersion in the 3D environment. Cubemap: First-person view of a 3D world To set up a VR environment in Bonsai, we first need to populate the 3D scene with objects, typically by adding textured 3D meshes. In this tutorial, the scene consists of a square room with four walls and a ground floor (Fig.2 Left). Fig.2: Left Flattened view of the room with the five textures — four walls and ground — seen from above; Center Cubmap view (image adapted from: SharkD ); Right Opengl coordinate system. Next, we create a view of the 3D environment from the perspective of the agent. In Bonsai, this is achieved using a Cubemap View centered at the agent’s location. The Cubemap View is part of the shaders library and renders the environment onto the six faces of a cube (+X, -X, +Y, -Y, +Z, -Z), generating a full 360° panoramic view of the scene (Fig.2 Center). Notably, in Bonsai shaders, the Y-axis points upward and the agent's default forward direction is along the -Z axis (Fig.2 Right). The following workflow renders a single view of the Cubemap applied to our 3D scene from the perspective of the agent. Creates a shader window that will render the 3D world, and loads resources related to BonVision, and the textures that will be used to cover the walls and the floor. Renders each frame of to be sent to the display. The RenderFrame node emits a notification whenever the image of our display device is to be updated. Creates the Cubemap view of the environment as mentioned above. At this stage, the cubemap is located at (0,0) looking forward, in the -Z direction. Emits a notification to the Draw subject, with the current perspective of the cubemap to draw the virtual world according to that view (3). Renders the cubemap from its current perspective. Creates a Viewpoint to visualize a part of the cubemap. You can change this view point by modifying the rotation and translation positions of the windows' viewpoint. Draws the 3D world according to the perspective of the cubemap (or given the transform it entails in 1). The frive branches draw (from top to bottom) the front, back, right, left and floor textures. This is the resulting image generated in the output window: Fig.3: Snapshot of the the 3d scene rendered from the camera's point of view. Navigating in the virtual world To navigate the 3D world, we need to update the cubemap’s position and orientation to match the agent’s movements. First, we define how the agent moves. In this example, we use a simple video game–style control scheme: the W and S keys move the agent forward and backward, while the A and D keys rotate it left and right. The following workflow shows how to implement this in Bonsai: Updates the current camera angle whenever keys A or D are pressed. Accumulates the rotation angle Sets the CameraOrientation subject with the updated rotation angle of the camera Updates the current position of the camera whenever keys W or S are pressed. Calculates the forward/backward translation vector given the current orientation of the camera Creates a Vector3 with the X,Y, Z translation of the camera Accumulates the translation vector Sets the CameraPosition subject with the updated position of the camera Once we know the camera’s position and orientation, we need to update its cubemap ViewMatrix to reflect the corresponding translation and rotation. This matrix ensures that each face of the cubemap points in the correct direction. Here’s how we can implement this: Encapsulates the Shaders initialization, the 3D Scene drawing and the Navigation workflows we described above. Renders each frame of to be sent to the display. Updates the current position of the camera by setting the Eye property of the CubemapView node. Applies a rotation to the cubemap ViewMatrix, around the Y axis, using the current orientation of the camera. Re-creates the output of the CubemapView node with the updated ViewMatrix. Emits a notification to the Draw subject, with the current perspective of the cubemap, to draw the 3D scene. A visualization of the final 3D scene rendering, showing the agent navigating the VR environment, is shown in Fig.4. Fig.4: Navigation in the 3D space. Creating a panoramic view of the cubemap To create a panoramic view of the cubemap spanning angles greater than 90º, we use a shader that projects the cubemap’s faces onto a cylindrical surface, producing a continuous panoramic image. A shader is a small program that runs directly on the graphics card (GPU) and controls how 3D data is transformed into the final image displayed on screen. There are three main types of shaders: Vertex shader (.vert): Runs once per vertex. It transforms 3D coordinates—position, normals, and texture coordinates—into the camera’s coordinate system. Fragment shader (.frag): Runs once per pixel (fragment). It determines the color of each pixel by combining textures, lighting, and material properties. Geometry, tessellation, and compute shaders (advanced): Add extra geometry, refine details, or perform general GPU computations not directly tied to pixels. In this tutorial, we will use only a vertex and a fragment shaders. The vertex shader (panoramic.vert) is minimal, and its purpose is to draw a quad covering the entire screen: #version 400 // Use GLSL version 4.00 layout(location = 0) in vec2 vp; // Input vertex attribute at location 0: // a 2D position (clip-space coords [-1,1]) out vec2 uv; // Output variable passed to the fragment shader void main() { uv = vp; // Forward the input position to fragment shader as \"uv\" gl_Position = vec4(vp, 0.0, 1.0); // Set the final clip-space position (z=0, w=1) } Our fragment shader (panoramic.frag) takes a fullscreen quad and maps it onto a cylindrical projection of a cubemap environment in the range [-110º,110º]. In other words, it transforms the cubemap into a continuous cylindrical panoramic image: #version 400 in vec2 uv; // Input from vertex shader: position of fragment on quad [-1,1] out vec4 fragColor; // Output color uniform samplerCube cubeMap; // Cubemap texture (environment) uniform float height = 1.0; // Cylinder height (full height, replaces hardcoded 0.5) uniform float angleStart = -110; // Start angle for the field of view uniform float angleEnd = 110; // End angle for the field of view void main() { // Convert uv from [-1,1] to [0,1] for easier mapping float u = uv.x * 0.5 + 0.5; // controls the horizontal angle float v = uv.y * 0.5 + 0.5; // controls the vertical position along the cylinder // Map u coordinate to the slice's angular range float thetaDeg = mix(angleStart, angleEnd, u); float theta = radians(thetaDeg); // Convert angle to radians // Compute lateral XZ direction of the ray in world space with forward along -Z vec3 dir = normalize(vec3(sin(theta), 0.0, -cos(theta))); // Map vertical position into cylinder height [-height/2, +height/2] dir.y = (v - 0.5) * height; // Clamp vertical coordinate so it stays inside cylinder dir.y = clamp(dir.y, -height/2.0, height/2.0); // Sample the cubemap texture fragColor = texture(cubeMap, dir); } These two files can be added to Bonsai by editing the Shaders property of the ShaderResource node, and assigning a Material that references the vertex and fragment shader files. The workflow below shows the complete Bonsai setup for rendering a panoramic view of our 3D environment. Encapsulates the 3D Scene drawing and the Navigation workflows we described above. Loads the resources necessary to run the new shader and mesh resources. Loads a Material named PanoramicShader that includes the panoramic.vert and panoramic.frag shader files. Loads a TextureQuad named PanoramicQuad that will be used to draw the shader into it. Renders each frame of to be sent to the display. Encapsulates the workflow required to translate and rotate the cubemap acording to the current position and orientation of the camera as described above. Emits a notification to the Draw subject, with the current perspective of the cubemap, to draw the 3D scene. Renders the cubemap Binds the rendered cubemap to the PanoramicShader. This tells the GPU which texture to sample and which shader program to execute during the next draw call Draws the PanoramicShader into our PanoramicQuad. Creates a view window to display the finished PanoramicQuad. The resulting panoramic rendering of the 3D scene is shown in Fig.5. Fig.5: panoramic rendering of the 3D scene. Slicing the panoramic view in three adjustable parts Often, a panoramic view needs to be divided into independent segments to match the physical layout of the display. In our setup, the projection requires three images—front and two mirrors—that must be produced in a way that, when projected to the canvas, gives the animal the impression of full immersion (see Fig.1). By splitting the panoramic image into three sections—left, front, and right—we can control each viewpoint independently and ensure that each portion aligns correctly with the cylindrical display surrounding the animal. The angles used for each view are: Left view: [-110º,-45º] Front view: [-45º,45º] Right view: [45º,110º] Here is the final code: Encapsulates the Shaders initialization, the 3D Scene drawing and the Navigation workflows we described above. Renders each frame of to be sent to the display. Sets the uniform variables angleStart and angleEnd, and draws a different view of the Cubemap in each branch out of the RenderCubemap. Binds the rendered cubemap to our PanoramicShader. This tells the GPU the code that it will need to run in the next draw call. Draws the PanoramicShader into our PanoramicQuad. Creates a view window to display the finished PanoramicQuad. Creates an off-screen framebuffer (texture) that captures a rendered view instead of drawing directly to the window. Binds the rendered view to the PanoramicShader. This tells the GPU which texture to sample and which shader program to execute during the next draw call. Draws the PanoramicShader into our PanoramicQuad. Creates a perspective mapping of the PanoramicQuad. This mapping lets us position the four vertices of the quad in display coordinates (by dragging the vertexes with the mouse), making it easy to align the projected image with mirrors and the cylindrical canvas. This is achieved by setting the Destination property of the PerspectiveMapping. Simply click on the Destination property textbox, then on the '...' symbol that appears on the right. This opens a window where you can draw a quadrilateral, or adjust the position of its vertices in case it is already exists. Draws the image from each view in the main window. The three views composing the final image as the agent navigates in the 3D scene are shown in Fig.6. Note that the side views need to be inverted around the vertical axis to compensate for their reflection from the mirrors. This inversion can be achieved by manually swapping the quad vertices along the vertical direction (see Fig.6). Adjusting these vertices also allows us to fine-tune the final projection, aligning it precisely with the positions of the mirrors and the cylindrical display in the real-world setup. Fig.6: Visualizing the three views of the 3D scence in one window while mirroring the left view image."
  }
}